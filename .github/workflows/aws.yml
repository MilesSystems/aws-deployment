name: Amazon Web Services

on:
  workflow_call:
    inputs:
      accountName:
        required: true
        type: string
      emailDomain:
        required: true
        type: string
      subnetIdentifier:
        required: true
        type: string
      regions:
        description: 'A comma separated list of regions to deploy to.'
        required: true
        type: string
      defaultRegion:
        description: 'The default region to use if regions is not provided. Not required, will default to the first region in regions if not provided.'
        required: false
        type: string
      deployDatabase:
        description: 'Whether to deploy the database (true/false)'
        required: false
        type: string
        default: 'true'
      databaseServerlessVersion:
        type: string
        description: Deployment mode
        default: "none"
      databaseRegions:
        description: 'A comma separated list of regions to deploy databases to. Not required, will default to defaultRegion if not provided.'
        required: false
        type: string
      databaseEngine:
        description: 'Database engine (MySQL, aurora, aurora-mysql, aurora-postgresql, MariaDB, PostgreSQL, Oracle, sqlserver)'
        required: false
        type: string
        default: 'aurora-mysql'
      databaseEngineVersion:
        description: 'Database engine version'
        required: false
        type: string
        default: ''
      databaseInstanceType:
        description: 'Database instance type'
        required: false
        type: string
        default: 'db.t4g.micro'
      databaseMasterUsername:
        description: 'Database master username'
        required: false
        type: string
        default: 'root'
      databaseMasterPassword:
        description: 'Database master password'
        required: false
        type: string
        default: 'password'
      databaseName:
        description: 'Database name'
        required: false
        type: string
        default: 'RdsDatabase'
      databaseMultiAZ:
        description: 'Multi-AZ deployment (true or false)'
        required: false
        type: string
        default: 'false'
      databasePubliclyAccessible:
        description: 'Publicly accessible (true or false)'
        required: false
        type: string
        default: 'false'
      databaseAllocatedStorage:
        description: 'Allocated storage (in GB)'
        required: false
        type: number
        default: 20
      databaseBackupRetentionPeriod:
        description: 'Backup retention period (in days)'
        required: false
        type: number
        default: 7
      databaseStorageType:
        description: 'Storage type (standard, gp2, io1)'
        required: false
        type: string
        default: 'gp2'
      databaseDeletionProtection:
        description: 'Deletion protection (true or false)'
        required: false
        type: string
        default: 'false'
      databasePreferredBackupWindow:
        description: 'Preferred backup window (hh24:mi-hh24:mi)'
        required: false
        type: string
        default: '23:25-23:55'
      databasePreferredMaintenanceWindow:
        description: 'Preferred maintenance window (ddd:hh24:mi-ddd:hh24:mi)'
        required: false
        type: string
        default: 'Tue:02:00-Tue:05:00'
      databaseScalingConfigurationAutoPause:
        description: 'Auto pause for Aurora serverless (true or false)'
        required: false
        type: string
        default: true
      databaseScalingConfigurationMinCapacity:
        description: 'Minimum capacity for Aurora serverless'
        required: false
        type: number
        default: 1
      databaseScalingConfigurationMaxCapacity:
        description: 'Maximum capacity for Aurora serverless'
        required: false
        type: number
        default: 4
      databaseScalingConfigurationSecondsUntilAutoPause:
        description: 'Seconds until auto pause for Aurora serverless'
        required: false
        type: number
        default: 1800
      databaseStorageEncrypted:
        description: 'Storage encrypted (true or false)'
        required: false
        type: string
        default: false
      imageBuilderInstanceTypes:
        description: 'The EC2 instance type for the image builder'
        required: false
        type: string
        default: ''
      imageBuilderImagesToKeep:
        description: 'The number of images to keep'
        required: false
        type: number
        default: 4
      imageBuilderRegions:
        description: 'A comma separated list of regions, specifically a sub-set of the regions, to build images in. This is experimental and is not ready for production use. TODO - if a set larger than one but less than max, how do we determine the closest regions to send the images to. Not required, will default to defaultRegion if not provided.'
        required: false
        type: string
      imageBuilderScriptBuild:
        description: 'The script'
        required: false
        type: string
        default: ''
      imageBuilderScriptValidate:
        description: 'The script to run on the EC2 instance to validate the image, should have a shebang line at the top'
        required: false
        type: string
        default: ''
      imageBuilderForceRebuild:
        description: 'Force rebuild the image (true or false)'
        required: false
        type: string
        default: false
      imageBuilderBaseImageAMI:
        description: 'The base image AMI'
        required: false
        type: string
        default: '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64'
      deployALB:
        description: 'Deploy an Application Load Balancer (true or false)'
        required: false
        type: string
        default: true
      deployNLB:
        description: 'Deploy a Network Load Balancer (true or false)'
        required: false
        type: string
        default: false
      deployHeartbeatTimeout:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 1800 seconds (30 minutes).'
        required: false
        type: number
        default: 1800
      deployCreationPolicyTimeout:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 10 minutes.'
        required: false
        type: string
        default: 'PT10M'
      deployUpdatePolicyPauseTime:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 10 minutes.'
        required: false
        type: string
        default: 'PT10M'
      loadBalancerRulePriority:
        description: 'The priority of the rule'
        required: false
        type: number
        default: 1
      masterAccountOidcRole:
        required: false
        type: string
      networkAccountOidcRole:
        required: false
        type: string
      instanceDeploymentAccountOidcRole:
        required: false
        type: string
      environment:
        required: true
        type: string
      minimumRunningInstances:
        required: true
        type: number
        default: 0
      onDemandBaseCapacity:
        required: false
        type: number
        default: 1
      desiredInstanceCapacity:
        required: true
        type: number
        default: 1
      OnDemandPercentageAboveBaseCapacity:
        required: false
        type: number
        default: 0
      instanceType:
        required: false
        type: string
        default: 't3.micro'
      maximumRunningInstances:
        required: true
        type: number
      highlyAvailableNat:
        required: false
        type: boolean
        default: false
      enableVpcFlowLogs:
        required: false
        type: boolean
        default: false
      domains:
        description: 'A comma separated list of domains.'
        required: false
        type: string
        default: ''
      dockerBuildConfig:
        description: >
          Path to Dockerfile or docker-compose.yml. Use "Dockerfile" or "true" for default Dockerfile.
          Use "docker-compose.yml" or a path to a Compose file to use docker-compose.
          Leave empty to skip build.
        type: string
        default: ""
      deployK8Container:
        description: 'Deploy a Kubernetes container (true/false)'
        required: false
        type: string
        default: false
      k8sDeploymentManifestPath:
        description: Path to Kubernetes deployment YAML template (optional)
        type: string
        required: false
      k8sServiceManifestPath:
        description: Path to your Service manifest (optional)
        type: string
        required: false
      k8sDeploymentName:
        description: Name of the K8s Deployment (used if no manifest)
        type: string
        required: false
        default: my-deployment
      k8sContainerName:
        description: Name of the container to update
        type: string
        required: false
        default: my-container
      eksClusterName:
        description: 'The EKS cluster name for K8 deployments'
        required: false
        type: string
        default: ''
      ecrRepository:
        description: 'The ECR repository URI (for Docker container images). Use the repository name (e.g. "my-app")—this workflow will create it if it doesn’t exist.'
        required: false
        type: string
        default: ''
      deployUserDataScript:
        description: 'Deploy a user data script (true or false)'
        required: false
        type: string
        default: ''
      deployTrackUserDataScript:
        description: 'Deploy a track user data script (true or false)'
        required: false
        type: string
        default: ''
      cpuUtilizationToScale:
        description: 'CPU utilization to scale'
        required: false
        type: number
        default: 70
      secretPayloadEncrypted:
        description: 'Encrypted JSON containing secrets'
        required: false
        type: string

    secrets:
      ENCRYPTION_KEY:
        required: false

permissions:
  id-token: write
  contents: read

jobs:
  CONSTANTS:
    runs-on: ubuntu-latest
    outputs:
      repositoryNicename: ${{ steps.account.outputs.repositoryNicename }}
      repository: ${{ steps.account.outputs.repository }}
      deploymentAccountId: ${{ steps.account.outputs.deploymentAccountId }}
      networkingAccountId: ${{ steps.account.outputs.networkingAccountId }}
      currentBranch: ${{ steps.account.outputs.currentBranch }}
      vpcCidrParam: ${{ steps.network.outputs.vpcCidrParam }}
      highlyAvailableNat: ${{ steps.network.outputs.highlyAvailableNat }}
      enableVpcFlowLogs: ${{ steps.network.outputs.enableVpcFlowLogs }}
      privateAZASubnetBlock: ${{ steps.network.outputs.privateAZASubnetBlock }}
      publicAZASubnetBlock: ${{ steps.network.outputs.publicAZASubnetBlock }}
      dataAZASubnetBlock: ${{ steps.network.outputs.dataAZASubnetBlock }}
      privateAZBSubnetBlock: ${{ steps.network.outputs.privateAZBSubnetBlock }}
      publicAZBSubnetBlock: ${{ steps.network.outputs.publicAZBSubnetBlock }}
      dataAZBSubnetBlock: ${{ steps.network.outputs.dataAZBSubnetBlock }}
      privateAZCSubnetBlock: ${{ steps.network.outputs.privateAZCSubnetBlock }}
      publicAZCSubnetBlock: ${{ steps.network.outputs.publicAZCSubnetBlock }}
      dataAZCSubnetBlock: ${{ steps.network.outputs.dataAZCSubnetBlock }}
      regionInformation: ${{ steps.regions.outputs.regionInformation }}
      databaseRegionInformation: ${{ steps.regions.outputs.databaseRegionInformation }}
      imageBuilderRegionInformation: ${{ steps.regions.outputs.imageBuilderRegionInformation }}
      defaultRegion: ${{ steps.regions.outputs.defaultRegion }}
      secrets: ${{ steps.secrets.outputs.secrets }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Install JQ utility
        run: sudo apt-get install jq

      - name: Fetch all tags
        run: git fetch --all --tags

      - name: Validate inputs and process payload
        run: |
          if [ -n "${{ inputs.secretPayloadEncrypted }}" ]; then
            if [ -z "${{ secrets.ENCRYPTION_KEY }}" ]; then
              echo "::error::inputs.secretPayloadEncrypted is set but secrets.ENCRYPTION_KEY is missing."
              exit 1
            fi
          elif [ -n "${{ secrets.ENCRYPTION_KEY }}" ]; then
            echo "::warning::secrets.ENCRYPTION_KEY is set but inputs.secretPayloadEncrypted is not provided."
          fi

      - name: Account / Environment / Auto Scaling Variables
        id: account
        run: |
          echo "repo=${GITHUB_REPOSITORY##*/}" >> $GITHUB_OUTPUT
          echo "ref=${GITHUB_REF}" >> $GITHUB_OUTPUT
          DEFAULT_GIT_BRANCH=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@')
          echo "default_branch=${DEFAULT_GIT_BRANCH}" >> $GITHUB_OUTPUT
          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
          echo "currentBranch=${CURRENT_BRANCH}" >> $GITHUB_OUTPUT
          REPO_NAME="${GITHUB_REPOSITORY##*/}"
          echo "repository=${REPO_NAME}" >> $GITHUB_OUTPUT
          echo "repositoryNicename=${REPO_NAME//./-}" >> $GITHUB_OUTPUT
          if [ -z "${{ inputs.instanceDeploymentAccountOidcRole }}" ] || [ -z "${{ inputs.networkAccountOidcRole }}" ]; then
            echo "Error: instanceDeploymentAccountOidcRole and networkAccountOidcRole must be provided."
            exit 1
          fi
          DEPLOYMENT_ACCOUNT_ID=$( echo "${{ inputs.instanceDeploymentAccountOidcRole }}" | cut -d':' -f5 )
          NETWORK_ACCOUNT_ID=$( echo "${{ inputs.networkAccountOidcRole }}" | cut -d':' -f5 )
          echo "deploymentAccountId=${DEPLOYMENT_ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "networkingAccountId=${NETWORK_ACCOUNT_ID}" >> $GITHUB_OUTPUT

      - name: Set AWS Subnet Blocks
        id: network
        run: |
          set -eEBx
          chmod +x ./.github/assets/shell/setSubnets.sh
          ./.github/assets/shell/setSubnets.sh \
            "${{ inputs.subnetIdentifier }}" \
            "${{ inputs.highlyAvailableNat }}" \
            "${{ inputs.enableVpcFlowLogs }}" \
            "$GITHUB_OUTPUT"

      - name: Process Regions
        id: regions
        run: |
          REGIONS=(${{ inputs.regions }})

          # Set DEFAULT_REGION to the first region in regions if defaultRegion is not provided
          if [ -z "${{ inputs.defaultRegion }}" ]; then
            DEFAULT_REGION="${REGIONS[0]}"
          else
            DEFAULT_REGION="${{ inputs.defaultRegion }}"
          fi

          # Set DATABASE_REGIONS to defaultRegion if databaseRegions is not provided
          if [ -z "${{ inputs.databaseRegions }}" ]; then
            DATABASE_REGIONS=($DEFAULT_REGION)
          else
            DATABASE_REGIONS=(${{ inputs.databaseRegions }})
          fi

          if [ -z "${{ inputs.imageBuilderRegions }}" ]; then
            IMAGE_BUILDER_REGIONS=($DEFAULT_REGION)
          else
            IMAGE_BUILDER_REGIONS=(${{ inputs.imageBuilderRegions }})
          fi

          REGION_MATRIX=$(jq -n --arg regions "${{ inputs.regions }}" '{"aws-region": ($regions | split(","))}')
          DATABASE_REGION_MATRIX=$(jq -n --arg regions "$(echo "${DATABASE_REGIONS[*]}" | tr ' ' ',')" '{"aws-region": ($regions | split(","))}')
          IMAGE_BUILDER_REGIONS_MATRIX=$(jq -n --arg regions "$(echo "${IMAGE_BUILDER_REGIONS[*]}" | tr ' ' ',')" '{"aws-region": ($regions | split(","))}')

          echo "regionInformation=$(echo $REGION_MATRIX | jq -c)" >> $GITHUB_OUTPUT
          echo "defaultRegion='${DEFAULT_REGION}'" >> $GITHUB_OUTPUT
          echo "databaseRegionInformation=$(echo $DATABASE_REGION_MATRIX | jq -c)" >> $GITHUB_OUTPUT
          echo "imageBuilderRegionInformation=$(echo $IMAGE_BUILDER_REGIONS_MATRIX | jq -c)" >> $GITHUB_OUTPUT

          echo "DEFAULT_REGION: ${DEFAULT_REGION}"
          echo "REGION_MATRIX: ${REGION_MATRIX}"
          echo "DATABASE_REGION_MATRIX: ${DATABASE_REGION_MATRIX}"
          echo "IMAGE_BUILDER_REGIONS_MATRIX: ${IMAGE_BUILDER_REGIONS_MATRIX}"

  SHARED-NETWORKING:
    outputs:
      vpc: ${{ steps.export-vpc.outputs.vpc }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: CONSTANTS
    steps:
      - name: Configure AWS credentials for Shared Networking Account (${{ needs.CONSTANTS.outputs.networkingAccountId }}) (${{ inputs.networkAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.networkAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Deploy VPC stack
        run: |
          if ! aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ inputs.accountName }}-network; then
            ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} ${{ inputs.accountName }}-network \
              --template-body file://CloudFormation/vpc.yaml \
              --parameters \
                ParameterKey=VpcCidrParam,ParameterValue="${{ needs.CONSTANTS.outputs.vpcCidrParam }}"  \
                ParameterKey=PrivateAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZASubnetBlock }}"  \
                ParameterKey=PublicAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZASubnetBlock }}"  \
                ParameterKey=DataAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZASubnetBlock }}"  \
                ParameterKey=PrivateAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZBSubnetBlock }}"  \
                ParameterKey=PublicAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZBSubnetBlock }}"  \
                ParameterKey=DataAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZBSubnetBlock }}"  \
                ParameterKey=PrivateAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZCSubnetBlock }}"  \
                ParameterKey=PublicAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZCSubnetBlock }}"  \
                ParameterKey=DataAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZCSubnetBlock }}"  \
                ParameterKey=HighlyAvailableNat,ParameterValue="${{ needs.CONSTANTS.outputs.highlyAvailableNat }}"  \
                ParameterKey=EnableVpcFlowLogs,ParameterValue="${{ needs.CONSTANTS.outputs.enableVpcFlowLogs }}"
          
            echo "Sleeping for 240 seconds to allow VPC stack exports to propagate. We've seen timing issues with the VPC stack exports not being available immediately for networkshares."
            sleep 240
          
          else
            echo "The VPC stack already exists on the AWS network account."
          fi

      - name: Sharing VPC network from (${{ needs.CONSTANTS.outputs.networkingAccountId }}) to (${{ needs.CONSTANTS.outputs.deploymentAccountId }})
        run: |
          if ! aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ inputs.accountName }}-networkshares; then
            ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} ${{ inputs.accountName }}-networkshares \
                    --template-body file://./CloudFormation/network.yaml \
                    --parameters \
                      ParameterKey=NetworkStackName,ParameterValue="${{ inputs.accountName }}-network" \
                      ParameterKey=Environment,ParameterValue="${{ inputs.environment }}" \
                      ParameterKey=AccountId,ParameterValue="${{ needs.CONSTANTS.outputs.deploymentAccountId }}"
          fi

      - name: Export VPC ID
        id: export-vpc
        run: |
          VPC_ID=$(aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ inputs.accountName }}-network --query 'Stacks[0].Outputs[?OutputKey==`VpcId`].OutputValue' --output text)
          echo "vpc=${VPC_ID}" >> $GITHUB_OUTPUT

  REGIONAL-NETWORKING:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [CONSTANTS, SHARED-NETWORKING]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{ inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Get AWS Subnet IDs
        run: |
          
          set -eEBx
          
          # dont use source here so variable usage is explicit
          chmod +x ./.github/assets/shell/getSubnets.sh
          
          ./.github/assets/shell/getSubnets.sh \
            "${{ needs.SHARED-NETWORKING.outputs.vpc }}" \
            "${{ matrix.aws-region }}" \
            "${{ needs.CONSTANTS.outputs.deploymentAccountId }}" \
            "${{ needs.CONSTANTS.outputs.privateAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.privateAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.privateAZCSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZCSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZCSubnetBlock }}" \
            "$GITHUB_ENV"

      - name: aws stack iam
        if: ${{ matrix.aws-region == 'us-east-1' }}
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} iam \
          --template-body file://./CloudFormation/iam.yaml \
          --capabilities CAPABILITY_NAMED_IAM

      - name: aws stack sg
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} sg \
          --template-body file://./CloudFormation/sg.yaml \
          --parameters \
          ParameterKey=VpcId,ParameterValue="\"${{ env.vpc }}\""

      - name: aws ec2 get security group
        run: |
          SECURITY_GROUP="$( aws ec2 describe-security-groups --query 'SecurityGroups[].GroupId' --filters Name=group-name,Values=\*Ec2\* --output text )"
          if [[ "" != "$SECURITY_GROUP" ]]; then
            echo "The Ec2 security group was found."
          else
            echo "No Ec2 security group was found. The Security group is created in sg.yaml"
            exit 1;
          fi
          echo "security=$SECURITY_GROUP" >> REGIONAL-NETWORKING.txt

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "REGIONAL-NETWORKING.sh"
          done < "REGIONAL-NETWORKING.txt"
          cat REGIONAL-NETWORKING.sh

      - name: Upload subnet IDs artifact
        uses: actions/upload-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./REGIONAL-NETWORKING.sh

  # New job to ensure ECR repository exists and set up EKS if needed
  SETUP-ECR-K8S:
    if: ${{ inputs.ecrRepository != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.imageBuilderRegionInformation) }}
    name: Setup ECR and K8s
    runs-on: ubuntu-latest
    needs: [CONSTANTS, REGIONAL-NETWORKING]
    outputs:
      ecrRepoUri: ${{ steps.ecr.outputs.ecrRepoUri }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Configure AWS credentials for ECR setup
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Ensure ECR repository exists
        id: ecr
        run: |
          # Use the input as the repository name
          REPO_NAME="${{ inputs.ecrRepository }}"
          if [ -z "$REPO_NAME" ]; then
            echo "No ECR repository name provided. Skipping ECR setup."
            echo "ecrRepoUri=" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "Using ECR repository name: $REPO_NAME"
          if aws ecr describe-repositories --repository-names "$REPO_NAME" > /dev/null 2>&1; then
            echo "Repository $REPO_NAME exists."
          else
            echo "Repository $REPO_NAME does not exist. Creating..."
            aws ecr create-repository --repository-name "$REPO_NAME"
          fi
          REPO_URI=$(aws ecr describe-repositories --repository-names "$REPO_NAME" --query "repositories[0].repositoryUri" --output text)
          echo "ecrRepoUri=$REPO_URI" >> $GITHUB_OUTPUT

      - name: Ensure EKS cluster exists
        if: ${{ inputs.eksClusterName != '' }}
        run: |
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
      
          if ! aws eks describe-cluster --name ${{ inputs.eksClusterName }} --region "${{ matrix.aws-region }}" > /dev/null 2>&1; then
            echo "Cluster not found. Creating EKS cluster..."
            eksctl create cluster \
              --name "${{ inputs.eksClusterName }}" \
              --region "${{ matrix.aws-region }}" \
              --nodes 2 \
              --nodegroup-name "ng-${{ inputs.eksClusterName }}" \
              --version "1.29"
          else
            echo "EKS cluster ${{ inputs.eksClusterName }} already exists."
          fi

      - name: Generate kubeconfig for EKS (if provided)
        if: ${{ inputs.eksClusterName != '' }}
        run: |
          set -eEBx
          echo "Creating kubeconfig for cluster: ${{ inputs.eksClusterName }}"
          aws eks update-kubeconfig --name ${{ inputs.eksClusterName }} --region "${{ matrix.aws-region }}"

  LOAD-BALANCERS:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [CONSTANTS, REGIONAL-NETWORKING]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh
      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{ inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh   

      - name: Get ACM certificates
        if: ${{ inputs.domains != '' }}
        id: certificates
        run: |
          cat ./.github/assets/shell/getAmazonCertificateManagerSSL.sh
          source ./.github/assets/shell/getAmazonCertificateManagerSSL.sh "${{ inputs.domains }}"

      - name: Deploy ALB stack
        if: ${{ inputs.deployALB == 'true' }}
        run: |
          
          set -eEBx
          php "./.github/assets/php/createAlbYaml.php" "${{ steps.certificates.outputs.certificates }}" > ./CloudFormation/alb.yaml
          cat ./CloudFormation/alb.yaml
          sleep 3
          ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} alb \
            --template-body file://./CloudFormation/alb.yaml \
            --parameters 'ParameterKey=PublicSubnets,ParameterValue="${{ env.publicSubnet }}"'
      - name: Deploy NLB stack
        if: ${{ inputs.deployNLB == 'true' }}
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} nlb \
          --template-body file://./CloudFormation/nlb.yaml \
          --parameters  \
          ParameterKey=VpcId,ParameterValue="${{ env.vpc }}" \
          ParameterKey=PublicSubnets,ParameterValue="${{ env.publicAZASubnet }}"

      # It is possible for no variables to be in this file, so we touch it first
      - name: Create ENV variables
        run: |
          touch LOAD-BALANCERS.txt
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "LOAD-BALANCERS.sh"
          done < "LOAD-BALANCERS.txt"
          touch LOAD-BALANCERS.sh
          cat LOAD-BALANCERS.sh

      - name: Upload load balancer artifact
        uses: actions/upload-artifact@v4
        with:
          name: LOAD-BALANCERS-${{ matrix.aws-region }}
          path: ./LOAD-BALANCERS.sh
  DATABASE:
    if: ${{ inputs.deployDatabase == 'true' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.databaseRegionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, REGIONAL-NETWORKING ]
    steps:
      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{  inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          source ./REGIONAL-NETWORKING.sh
          cat REGIONAL-NETWORKING.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Deploy AWS RDS (database) stack
        run: |
          # Determine the subnet to use based on the input
          if [ "${{ inputs.databasePubliclyAccessible }}" = "true" ]; then
            DATA_SUBNET="${{ env.publicSubnet }}"
          else
            DATA_SUBNET="${{ env.dataSubnet }}"
          fi
          echo "Using subnet: $DATA_SUBNET"
        
          # Run the CloudFormation script
          ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} rds-database \
          --template-body file://./CloudFormation/database.yaml \
          --parameters \
            ParameterKey=VpcCidr,ParameterValue="${{ needs.CONSTANTS.outputs.vpcCidrParam }}" \
            ParameterKey=VpcId,ParameterValue="${{ env.vpc }}" \
            "ParameterKey=DataSubnets,ParameterValue=\"$DATA_SUBNET\"" \
            ParameterKey=DatabaseEngine,ParameterValue="${{ inputs.databaseEngine }}" \
            ParameterKey=DatabaseEngineVersion,ParameterValue="${{ inputs.databaseEngineVersion }}" \
            ParameterKey=ServerlessVersion,ParameterValue="${{ inputs.databaseServerlessVersion }}" \
            ParameterKey=DatabaseInstanceType,ParameterValue="${{ inputs.databaseInstanceType }}" \
            ParameterKey=DatabaseMasterUsername,ParameterValue="${{ inputs.databaseMasterUsername }}" \
            ParameterKey=DatabaseMasterPassword,ParameterValue="${{ inputs.databaseMasterPassword }}" \
            ParameterKey=DatabaseName,ParameterValue="${{ inputs.databaseName }}" \
            ParameterKey=MultiAZ,ParameterValue="${{ inputs.databaseMultiAZ }}" \
            ParameterKey=PubliclyAccessible,ParameterValue="${{ inputs.databasePubliclyAccessible }}" \
            ParameterKey=AllocatedStorage,ParameterValue="${{ inputs.databaseAllocatedStorage }}" \
            ParameterKey=BackupRetentionPeriod,ParameterValue="${{ inputs.databaseBackupRetentionPeriod }}" \
            ParameterKey=StorageType,ParameterValue="${{ inputs.databaseStorageType }}" \
            ParameterKey=DeletionProtection,ParameterValue="${{ inputs.databaseDeletionProtection }}" \
            ParameterKey=PreferredBackupWindow,ParameterValue="${{ inputs.databasePreferredBackupWindow }}" \
            ParameterKey=PreferredMaintenanceWindow,ParameterValue="${{ inputs.databasePreferredMaintenanceWindow }}" \
            ParameterKey=StorageEncrypted,ParameterValue="${{ inputs.databaseStorageEncrypted }}" \
            ParameterKey=ScalingConfigurationMinCapacity,ParameterValue="${{ inputs.databaseScalingConfigurationMinCapacity }}" \
            ParameterKey=ScalingConfigurationMaxCapacity,ParameterValue="${{ inputs.databaseScalingConfigurationMaxCapacity }}"

          # Fetch the Aurora security group
          AURORA_SECURITY_GROUP=$(aws ec2 describe-security-groups --query 'SecurityGroups[].GroupId' --filters Name=group-name,Values=*rds* --output text | tr -d '\r')
          
          # Check if the security group was found
          if [[ -z "$AURORA_SECURITY_GROUP" ]]; then
            echo "Error: No Aurora security group was found. The security group should be created automatically by the Aurora cluster."
            exit 1
          fi
          
          echo "Aurora Security Group: $AURORA_SECURITY_GROUP"
          
          # Output the security group ID
          echo "rds-security=$AURORA_SECURITY_GROUP" >> DATABASE.txt

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "DATABASE.sh"
          done < "DATABASE.txt"
          cat DATABASE.sh

      - name: Upload RDS security group artifact
        uses: actions/upload-artifact@v4
        with:
          name: DATABASE-${{ matrix.aws-region }}
          path: ./DATABASE.sh

  DOCKER-CONTAINER:
    if: ${{ inputs.dockerBuildConfig != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    needs: [CONSTANTS, SETUP-ECR-K8S]
    runs-on: ubuntu-latest
    env:
      IMAGE_TAG: ${{ github.sha }}
    outputs:
      ecr_uri: ${{ steps.ecr-login.outputs.ecr_uri }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build Docker Image
        run: |
          CONFIG="${{ inputs.dockerBuildConfig }}"
          echo "Building image from: $CONFIG"
  
          if [[ "$CONFIG" == "true" || "$CONFIG" == "Dockerfile" ]]; then
            echo "Using default Dockerfile"
            docker build -t myapp:$IMAGE_TAG .
          elif [[ "$CONFIG" == *".yml" || "$CONFIG" == *".yaml" ]]; then
            echo "Using Compose file: $CONFIG"
            docker compose -f "$CONFIG" build
            docker tag myapp_web myapp:$IMAGE_TAG  # change myapp_web to your service
          elif [[ "$CONFIG" == *"Dockerfile"* ]]; then
            echo "Using custom Dockerfile: $CONFIG"
            docker build -f "$CONFIG" -t myapp:$IMAGE_TAG .
          else
            echo "Unsupported dockerBuildConfig value: $CONFIG"
            exit 1
          fi

      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{ inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Login to Amazon ECR manually and set ECR_URI
        id: ecr-login
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          REGION=${{ matrix.aws-region }}
          REPO=${{ inputs.ecrRepository }}
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/${REPO}"
  
          echo "Logging into ECR: $ECR_URI"
          aws ecr get-login-password --region "$REGION" | docker login --username AWS --password-stdin "${AWS_ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com"
  
          echo "ecr_uri=$ECR_URI" >> $GITHUB_OUTPUT

      - name: Tag and Push Docker Image to ECR
        run: |
          docker tag myapp:$IMAGE_TAG ${{ steps.ecr-login.outputs.ecr_uri }}:$IMAGE_TAG
          docker push ${{ steps.ecr-login.outputs.ecr_uri }}:$IMAGE_TAG

  K8S-DEPLOY:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    if: ${{ inputs.deployK8Container == 'true' && inputs.eksClusterName != '' && inputs.ecrRepository != '' }}
    needs: [CONSTANTS, DOCKER-CONTAINER, DATABASE]
    runs-on: ubuntu-latest
    env:
      IMAGE_TAG: ${{ github.sha }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --name ${{ inputs.eksClusterName }} --region ${{ matrix.aws-region }}

      - name: Deploy to Kubernetes
        run: |
          IMAGE_URI="${{ needs.DOCKER-CONTAINER.outputs.ecr_uri }}:${{ github.sha }}"
          echo "Deploying image: $IMAGE_URI"
          
          # Replace image in deployment manifest
          sed "s|<REPLACEME_WITH_IMAGE>|$IMAGE_URI|g" "${{ inputs.k8sDeploymentManifestPath }}" > rendered-deployment.yaml
          kubectl apply -f rendered-deployment.yaml
          
          # Optionally apply a Service manifest
          if [[ -f "${{ inputs.k8sServiceManifestPath }}" ]]; then
            echo "Applying service from ${{ inputs.k8sServiceManifestPath }}"
            kubectl apply -f "${{ inputs.k8sServiceManifestPath }}"
          else
            echo "No service manifest found or provided"
          fi

  IMAGE-BUILDER:
    if: ${{ inputs.imageBuilderScriptBuild != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.imageBuilderRegionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, REGIONAL-NETWORKING ]
    steps:
      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{  inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat ./REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Get or create infrastructure configuration
        run: |
          
          set -eEBx
          
          # Determine the instance types to use
          if [ -z "${{ inputs.imageBuilderInstanceTypes }}" ]; then
            INSTANCE_TYPES=${{ inputs.instanceType }}
          else
            INSTANCE_TYPES="${{ inputs.imageBuilderInstanceTypes }}"
          fi
          
          INFRASTRUCTURE_ARGUMENTS=(
            --instance-profile-name EC2RoleForImageBuilder 
            --subnet-id $publicAZASubnet 
            --instance-types $INSTANCE_TYPES
            --security-group-ids ${{ env.security }}  ${{ env.rds-security }} 
          )
          
          EXISTING_INFRA_CONFIG=$(aws imagebuilder list-infrastructure-configurations \
          --filter name=name,values=development-infrastructure-configuration \
          --query 'infrastructureConfigurationSummaryList[?name==`development-infrastructure-configuration`].arn' \
          --output text)
          
          if [[ -z "$EXISTING_INFRA_CONFIG" ]]; then
          aws imagebuilder create-infrastructure-configuration "${INFRASTRUCTURE_ARGUMENTS[@]}" \
          --name development-infrastructure-configuration
          else
            echo "Infrastructure configuration already exists: $EXISTING_INFRA_CONFIG"
          fi
          
          ARN=$(aws imagebuilder list-infrastructure-configurations \
            --filter name=name,values=development-infrastructure-configuration \
            --query 'infrastructureConfigurationSummaryList[?name==`development-infrastructure-configuration`].arn' \
            --output text)

          aws imagebuilder update-infrastructure-configuration --infrastructure-configuration-arn "$ARN" "${INFRASTRUCTURE_ARGUMENTS[@]}"

          echo "infrastructure=$ARN" >> $GITHUB_ENV
          echo "infrastructure=$ARN" >> $GITHUB_OUTPUT


      - name: Dynamic Region
        id: region
        run: |
          
          # Convert the regions array to a JSON array
          php  "./.github/assets/php/createAmiDistribution.php" "${{ needs.CONSTANTS.outputs.deploymentAccountId }}" "${{ needs.CONSTANTS.outputs.networkingAccountId }}" '${{ needs.CONSTANTS.outputs.imageBuilderRegionInformation }}' > amiDistribution.json 
          
          echo "AMI Distribution JSON:"
          cat amiDistribution.json

          # Check if the file was created successfully
          if [ $? -ne 0 ]; then
            exit 97
          fi

          # Print the filename on success - this works as it is only used locally in this job
          # dynamic files will be destroyed after any job is done
          echo "name=amiDistribution.json" >> $GITHUB_ENV
          echo "name=amiDistribution.json" >> $GITHUB_OUTPUT

      - name: Create or update distribution configuration
        id: distribution
        run: |
          
          set -eEBx
          
          DYNAMIC_REGION="${{ steps.region.outputs.name }}"

          DISTRIBUTION_ARGUMENTS=(
            --cli-input-json "file://$DYNAMIC_REGION"
          )

          DISTRIBUTIONS=$(aws imagebuilder list-distribution-configurations \
                            --filter 'name=name,values=${{ inputs.accountName }}-distribution-configuration' \
                            --query 'distributionConfigurationSummaryList[-1].arn' --output text | grep "${{ inputs.accountName }}" || echo "")

          if [[ -z "$DISTRIBUTIONS" ]]
          then
            aws imagebuilder create-distribution-configuration \
                        --name ${{ inputs.accountName }}-distribution-configuration \
                        "${DISTRIBUTION_ARGUMENTS[@]}"
            sleep 240
          else
            aws imagebuilder update-distribution-configuration \
                    --distribution-configuration-arn \
                        $(aws imagebuilder list-distribution-configurations --output text \
                                  --query 'distributionConfigurationSummaryList[-1].arn') \
                    "${DISTRIBUTION_ARGUMENTS[@]}"
          fi

          EXPORT_DISTRIBUTION=$(aws imagebuilder list-distribution-configurations \
                            --filter 'name=name,values=${{ inputs.accountName }}-distribution-configuration' \
                            --query 'distributionConfigurationSummaryList[-1].arn' --output text | grep "${{ inputs.accountName }}")

          echo "distribution=$EXPORT_DISTRIBUTION" >> $GITHUB_ENV
          echo "distribution=$EXPORT_DISTRIBUTION" >> IMAGE-BUILDER.txt

      - name: Create or update image builder
        id: imageBuilder
        run: |
          
          shopt -s failglob
          set -eEBxuo pipefail
          
          cat > ./imageBuilderScriptBuild <<'IMAGE-BUILDER-BUILD-EOF'
          ${{ inputs.imageBuilderScriptBuild }}
          IMAGE-BUILDER-BUILD-EOF
          
          cat > ./imageBuilderScriptValidate <<'IMAGE-BUILDER-VALIDATE-EOF'
          ${{ inputs.imageBuilderScriptValidate }}
          IMAGE-BUILDER-VALIDATE-EOF
          
          chmod +x ./.github/assets/shell/createUpdateImageBuilder.sh
          ./.github/assets/shell/createUpdateImageBuilder.sh \
            "${{ env.distribution }}" \
            "${{ matrix.aws-region }}" \
            "${{ inputs.environment }}" \
            "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
            "${{ secrets.ENCRYPTION_KEY }}" \
            "${{ inputs.secretPayloadEncrypted }}" \
            "${{ inputs.imageBuilderBaseImageAMI }}" \
            "${{ env.infrastructure }}"

      - name: Start image pipeline execution
        id: image
        run: |
          chmod +x ./.github/assets/shell/startImagePipelineExecution.sh
          source ./.github/assets/shell/startImagePipelineExecution.sh \
                "${{ inputs.environment }}" \
                "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
                "${{ inputs.imageBuilderImagesToKeep }}" \
                "${{ env.needImageRebuild }}" \
                "${{ inputs.imageBuilderForceRebuild }}"

      - name: Wait for image availability
        id: ami
        run: |
          set -eEBx
          source ./IMAGE-BUILDER.txt
          source ./.github/assets/shell/waitImageAvailable.sh \
              "${{ steps.image.outputs.image_arn }}" \
              "${{ inputs.environment }}" \
              "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
              "${{ steps.image.outputs.pipeline_arn }}" \
              "${{ matrix.aws-region }}" \
              "${{ github.head_ref || github.ref_name }}"

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "IMAGE-BUILDER.sh"
          done < "IMAGE-BUILDER.txt"
          cat IMAGE-BUILDER.sh

      - name: Upload IMAGE-BUILDER.sh artifact
        uses: actions/upload-artifact@v4
        with:
          name: IMAGE-BUILDER-${{ matrix.aws-region }}
          path: ./IMAGE-BUILDER.sh
  DEPLOY:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, REGIONAL-NETWORKING, DATABASE, IMAGE-BUILDER, LOAD-BALANCERS ]
    steps:
      - name: Configure AWS credentials for (${{ inputs.accountName }}) account (${{  inputs.instanceDeploymentAccountOidcRole }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ inputs.instanceDeploymentAccountOidcRole }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download REGIONAL-NETWORKING artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./
      - name: Download LOAD-BALANCERS artifact
        uses: actions/download-artifact@v4
        with:
          name: LOAD-BALANCERS-${{ matrix.aws-region }}
          path: ./

      - name: Download DATABASE artifact
        uses: actions/download-artifact@v4
        with:
          name: DATABASE-${{ matrix.aws-region }}
          path: ./

      - name: Download IMAGE-BUILDER artifact
        uses: actions/download-artifact@v4
        with:
          name: IMAGE-BUILDER-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat ./REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh
          cat ./DATABASE.sh
          source ./DATABASE.sh
          cat ./IMAGE-BUILDER.sh
          source ./IMAGE-BUILDER.sh
          cat ./LOAD-BALANCERS.sh
          source ./LOAD-BALANCERS.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Deploy web stack (${{ github.run_number }})
        id: web
        run: |
          
          cat > ./deployUserDataScript <<'DEPLOY-BOOTSTRAP-EOF'
          ${{ inputs.deployUserDataScript }}
          DEPLOY-BOOTSTRAP-EOF
          
          php ./.github/assets/php/createDeploymentUserDataYaml.php ./deployUserDataScript
          
          PARAMETERS_FILE=$( php ./.github/assets/php/createAwsJsonParametersFile.php \
                    --Environment=${{ inputs.environment }} \
                    --RepositoryNicename=${{ needs.CONSTANTS.outputs.repositoryNicename }} \
                    --Version=${{ env.version }} \
                    --RunNumber=${{ github.run_number }} \
                    --Branch=${{ github.head_ref || github.ref_name }} \
                    --GitHubRunNumber=${{ github.run_number }} \
                    --VpcId=${{ env.vpc }} \
                    --CertificateArns=${{ env.certificates }} \
                    --RecipeVersion=${{ env.version }} \
                    --PrivateSubnets=${{ env.privateSubnet }} \
                    --AmazonLinuxAMI=${{ env.ami }} \
                    --MinSize=${{ inputs.minimumRunningInstances }} \
                    --MaxSize=${{ inputs.maximumRunningInstances }} \
                    --DesiredCapacity=${{ inputs.desiredInstanceCapacity }} \
                    --OnDemandBaseCapacity=${{ inputs.onDemandBaseCapacity }} \
                    --OnDemandPercentageAboveBaseCapacity=${{ inputs.OnDemandPercentageAboveBaseCapacity }} \
                    --InstanceType=${{ inputs.instanceType }} \
                    --MaxCpu=${{ inputs.cpuUtilizationToScale }} \
                    --LoadBalancerRulePriority=${{ inputs.loadBalancerRulePriority }} \
                    --LoadBalancerHosts=${{ inputs.domains }} \
                    --AddAlbListener=${{ inputs.deployALB }} \
                    --HeartbeatTimeout=${{ inputs.deployHeartbeatTimeout }} \
                    --CreationPolicyTimeout=${{ inputs.deployCreationPolicyTimeout }} \
                    --UpdatePolicyPauseTime=${{ inputs.deployUpdatePolicyPauseTime }} \
                    --AddNlbListener=${{ inputs.deployNLB }} )
          
          echo "Parameters file:"
          
          cat $PARAMETERS_FILE
          
          cat > ./deployTrackUserDataScript <<'DEPLOY-BOOTSTRAP-EOF' 
          ${{ inputs.deployTrackUserDataScript }}
          DEPLOY-BOOTSTRAP-EOF
                    
          echo "Version (${{ env.version }})"
          
          source ./.github/assets/shell/stackWeb.sh "$PARAMETERS_FILE" \
            "${{ matrix.aws-region }}" "${{ inputs.environment }}" "${{ needs.CONSTANTS.outputs.repositoryNicename }}" "${{ env.version }}" "${{ github.run_number }}" "./deployTrackUserDataScript"

      - name: EC2 auto-scaling instance refresh
        if: ${{ steps.web.outputs.refresh == '1' && needs.IMAGE-BUILDER.outputs.image_rebuilt == '1' }}
        run: |
          REFRESH_ID=$(aws autoscaling start-instance-refresh \
                --preferences '{"InstanceWarmup": 1200, "MinHealthyPercentage": 100}' \
                --strategy Rolling \
                --auto-scaling-group-name "${{ inputs.environment }}-${{ needs.CONSTANTS.outputs.repositoryNicename }}-${{ env.version }}.${{ github.run_number }}-asg" --output text)

          TRY=-1

          getStatus() {
            STATUS=$(aws autoscaling describe-instance-refreshes \
                --instance-refresh-ids $REFRESH_ID \
                --query 'InstanceRefreshes[*]' \
                --auto-scaling-group-name "${{ inputs.environment }}-${{ needs.CONSTANTS.outputs.repositoryNicename }}-${{ env.version }}.${{ github.run_number }}-asg" | jq '.[-1].Status' --raw-output)
            TRY=$((1 + TRY))
          }

          cat > ./deployTrackUserDataScript <<'INSTANCE-REFRESH-EOF'
          ${{ inputs.deployTrackUserDataScript }}
          INSTANCE-REFRESH-EOF
          
          echo "Echo ./deployTrackUserDataScript: $( cat ./deployTrackUserDataScript )"

          getLog() {
            source ./.github/assets/shell/logBootStatus.sh "${{ env.version }}" "${{ github.run_number }}" "./deployTrackUserDataScript"
          } 

          getStatus

          sleep 240

          while [[ "$STATUS" == "Pending" || "$STATUS" == "InProgress" ]]; do
              getLog ${{ env.version }}
              echo "Waiting 60 seconds... <$STATUS> (attempt:$TRY)"
              sleep 60
              getStatus
          done
          if [[ "$STATUS" == "Successful" ]]; then
            echo "Refresh successful"
            aws ec2 describe-instances --query 'Reservations[*].Instances[*]' --filters Name=instance-state-name,Values=running --output text
            exit 0
          else
            aws cloudformation describe-stack-events --stack-name ${STACK_NAME} --region ${REGION}
            echo "Refresh failed ($STATUS)"
            exit 1
          fi
