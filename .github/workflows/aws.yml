name: Amazon Web Services

on:
  workflow_call:
    inputs:
      varsArtifactName:
        required: false
        type: string
        default: ''
      accountName:
        required: false
        type: string
      emailDomain:
        required: false
        type: string
      subnetIdentifier:
        required: false
        type: string
      regions:
        description: 'A comma separated list of regions to deploy to.'
        required: false
        type: string
      defaultRegion:
        description: 'The default region to use if regions is not provided. Not required, will default to the first region in regions if not provided.'
        required: false
        type: string
      deployDatabase:
        description: 'Whether to deploy the database (true/false)'
        required: false
        type: string
        default: 'true'
      databaseServerlessVersion:
        type: string
        description: Deployment mode
        default: "none"
      databaseRegions:
        description: 'A comma separated list of regions to deploy databases to. Not required, will default to defaultRegion if not provided.'
        required: false
        type: string
      databaseEngine:
        description: 'Database engine (MySQL, aurora, aurora-mysql, aurora-postgresql, MariaDB, PostgreSQL, Oracle, sqlserver)'
        required: false
        type: string
        default: 'aurora-mysql'
      databaseEngineVersion:
        description: 'Database engine version'
        required: false
        type: string
        default: ''
      databaseInstanceType:
        description: 'Database instance type'
        required: false
        type: string
        default: 'db.t4g.micro'
      databaseMasterUsername:
        description: 'Database master username'
        required: false
        type: string
        default: 'root'
      databaseMasterPassword:
        description: 'Database master password'
        required: false
        type: string
        default: 'password'
      databaseName:
        description: 'Database name'
        required: false
        type: string
        default: 'RdsDatabase'
      databaseInstanceIdentifierPrefix:
        description: 'Instance identifier prefix for RDS resources'
        required: false
        type: string
        default: 'mydb'
      databaseMultiAZ:
        description: 'Multi-AZ deployment (true or false)'
        required: false
        type: string
        default: 'false'
      databasePubliclyAccessible:
        description: 'Publicly accessible (true or false)'
        required: false
        type: string
        default: 'false'
      databaseAllocatedStorage:
        description: 'Allocated storage (in GB)'
        required: false
        type: number
        default: 20
      databaseBackupRetentionPeriod:
        description: 'Backup retention period (in days)'
        required: false
        type: number
        default: 7
      databaseStorageType:
        description: 'Storage type (standard, gp2, io1)'
        required: false
        type: string
        default: 'gp2'
      databaseDeletionProtection:
        description: 'Deletion protection (true or false)'
        required: false
        type: string
        default: 'false'
      databasePreferredBackupWindow:
        description: 'Preferred backup window (hh24:mi-hh24:mi)'
        required: false
        type: string
        default: '23:25-23:55'
      databasePreferredMaintenanceWindow:
        description: 'Preferred maintenance window (ddd:hh24:mi-ddd:hh24:mi)'
        required: false
        type: string
        default: 'Tue:02:00-Tue:05:00'
      databaseScalingConfigurationAutoPause:
        description: 'Auto pause for Aurora serverless (true or false)'
        required: false
        type: string
        default: true
      databaseScalingConfigurationMinCapacity:
        description: 'Minimum capacity for Aurora serverless'
        required: false
        type: number
        default: 1
      databaseScalingConfigurationMaxCapacity:
        description: 'Maximum capacity for Aurora serverless'
        required: false
        type: number
        default: 4
      databaseScalingConfigurationSecondsUntilAutoPause:
        description: 'Seconds until auto pause for Aurora serverless'
        required: false
        type: number
        default: 1800
      databaseStorageEncrypted:
        description: 'Storage encrypted (true or false)'
        required: false
        type: string
        default: false
      imageBuilderInstanceTypes:
        description: 'The EC2 instance type for the image builder'
        required: false
        type: string
        default: ''
      imageBuilderImagesToKeep:
        description: 'The number of images to keep'
        required: false
        type: number
        default: 4
      imageBuilderRegions:
        description: 'A comma separated list of regions, specifically a sub-set of the regions, to build images in. This is experimental and is not ready for production use. TODO - if a set larger than one but less than max, how do we determine the closest regions to send the images to. Not required, will default to defaultRegion if not provided.'
        required: false
        type: string
      imageBuilderScriptBuild:
        description: 'The script'
        required: false
        type: string
        default: ''
      imageBuilderScriptValidate:
        description: 'The script to run on the EC2 instance to validate the image, should have a shebang line at the top'
        required: false
        type: string
        default: ''
      imageBuilderForceRebuild:
        description: 'Force rebuild the image (true or false)'
        required: false
        type: string
        default: false
      imageBuilderBaseImageAMI:
        description: 'The base image AMI'
        required: false
        type: string
        default: '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64'
      volumeSize:
        description: 'The volume size in GB'
        required: false
        type: number
        default: 30
      deployALB:
        description: 'Deploy an Application Load Balancer (true or false)'
        required: false
        type: string
        default: true
      deployNLB:
        description: 'Deploy a Network Load Balancer (true or false)'
        required: false
        type: string
        default: false
      deployHeartbeatTimeout:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 1800 seconds (30 minutes).'
        required: false
        type: number
        default: 900
      deployCreationPolicyTimeout:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 10 minutes.'
        required: false
        type: string
        default: 'PT10M'
      deployUpdatePolicyPauseTime:
        description: 'How long the deployment script has to complete before the deployment is considered a failure. Default is 10 minutes.'
        required: false
        type: string
        default: 'PT10M'
      loadBalancerRulePriority:
        description: 'The priority of the rule'
        required: false
        type: number
        default: -1
      masterAccountOidcRole:
        required: false
        type: string
      networkAccountOidcRole:
        required: false
        type: string
      instanceDeploymentAccountOidcRole:
        required: false
        type: string
      environment:
        required: false
        type: string
      minimumRunningInstances:
        required: false
        type: number
        default: 0
      onDemandBaseCapacity:
        required: false
        type: number
        default: 1
      desiredInstanceCapacity:
        required: false
        type: number
        default: 1
      OnDemandPercentageAboveBaseCapacity:
        required: false
        type: number
        default: 0
      instanceType:
        required: false
        type: string
        default: 't3.micro'
      maximumRunningInstances:
        required: false
        type: number
      highlyAvailableNat:
        required: false
        type: boolean
        default: false
      enableVpcFlowLogs:
        required: false
        type: boolean
        default: false
      domains:
        description: 'A comma separated list of domains.'
        required: false
        type: string
        default: ''
      dockerBuildConfig:
        description: >
          Path to Dockerfile or docker-compose.yml. Use "Dockerfile" or "true" for default Dockerfile.
          Use "docker-compose.yml" or a path to a Compose file to use docker-compose.
          Leave empty to skip build.
        type: string
        default: ""
      deployK8Container:
        description: 'Deploy a Kubernetes container (true/false)'
        required: false
        type: string
        default: false
      k8sDeploymentManifestPath:
        description: Path to Kubernetes deployment YAML template (optional)
        type: string
        required: false
      k8sDeploymentName:
        description: Name of the K8s Deployment (used if no manifest)
        type: string
        required: false
        default: my-deployment
      k8sContainerName:
        description: Name of the container to update
        type: string
        required: false
        default: my-container
      eksClusterName:
        description: 'The EKS cluster name for K8 deployments'
        required: false
        type: string
        default: ''
      eksClusterVersion:
        description: 'The EKS cluster version for K8 deployments'
        required: false
        type: string
        default: '1.32'
      ecrRepository:
        description: 'The ECR repository URI (for Docker container images). Use the repository name (e.g. "my-app")—this workflow will create it if it doesn’t exist.'
        required: false
        type: string
        default: ''
      deployUserDataScript:
        description: 'Deploy a user data script (true or false)'
        required: false
        type: string
        default: ''
      deployTrackUserDataScript:
        description: 'Deploy a track user data script (true or false)'
        required: false
        type: string
        default: ''
      cpuUtilizationToScale:
        description: 'CPU utilization to scale'
        required: false
        type: number
        default: 70
      secretPayloadEncrypted:
        description: 'Encrypted JSON containing secrets'
        required: false
        type: string

    secrets:
      ENCRYPTION_KEY:
        required: false

permissions:
  id-token: write
  contents: read

jobs:
  FLAGS:
    runs-on: ubuntu-latest
    outputs:
      deployDatabase: ${{ steps.out.outputs.deployDatabase }}
      dockerBuildConfig: ${{ steps.out.outputs.dockerBuildConfig }}
      ecrRepository: ${{ steps.out.outputs.ecrRepository }}
      imageBuilderScriptBuild: ${{ steps.out.outputs.imageBuilderScriptBuild }}
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars
      - name: Normalize flags
        id: out
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "$f"
            cat "$f"
            . "$f"
          done
          
          echo "imageBuilderScriptBuild<<'EOF'"$'\n'"${imageBuilderScriptBuild:-${{ inputs.imageBuilderScriptBuild }}}"$'\n\'EOF\'\n' >> "$GITHUB_OUTPUT"
          echo "imageBuilderScriptValidate<<'EOF'"$'\n'"${imageBuilderScriptValidate:-${{ inputs.imageBuilderScriptValidate }}}"$'\n\'EOF\'\n' >> "$GITHUB_OUTPUT"
          echo "deployUserDataScript<<'EOF'"$'\n'"${deployUserDataScript:-${{ inputs.deployUserDataScript }}}"$'\n\'EOF\'\n' >> "$GITHUB_OUTPUT"
          echo "deployTrackUserDataScript<<'EOF'"$'\n'"${deployTrackUserDataScript:-${{ inputs.deployTrackUserDataScript }}}"$'\n\'EOF\'\n' >> "$GITHUB_OUTPUT"

  CONSTANTS:
    runs-on: ubuntu-latest
    outputs:
      repositoryNicename: ${{ steps.account.outputs.repositoryNicename }}
      repository: ${{ steps.account.outputs.repository }}
      deploymentAccountId: ${{ steps.account.outputs.deploymentAccountId }}
      networkingAccountId: ${{ steps.account.outputs.networkingAccountId }}
      currentBranch: ${{ steps.account.outputs.currentBranch }}
      vpcCidrParam: ${{ steps.network.outputs.vpcCidrParam }}
      highlyAvailableNat: ${{ steps.network.outputs.highlyAvailableNat }}
      enableVpcFlowLogs: ${{ steps.network.outputs.enableVpcFlowLogs }}
      privateAZASubnetBlock: ${{ steps.network.outputs.privateAZASubnetBlock }}
      publicAZASubnetBlock: ${{ steps.network.outputs.publicAZASubnetBlock }}
      dataAZASubnetBlock: ${{ steps.network.outputs.dataAZASubnetBlock }}
      privateAZBSubnetBlock: ${{ steps.network.outputs.privateAZBSubnetBlock }}
      publicAZBSubnetBlock: ${{ steps.network.outputs.publicAZBSubnetBlock }}
      dataAZBSubnetBlock: ${{ steps.network.outputs.dataAZBSubnetBlock }}
      privateAZCSubnetBlock: ${{ steps.network.outputs.privateAZCSubnetBlock }}
      publicAZCSubnetBlock: ${{ steps.network.outputs.publicAZCSubnetBlock }}
      dataAZCSubnetBlock: ${{ steps.network.outputs.dataAZCSubnetBlock }}
      regionInformation: ${{ steps.regions.outputs.regionInformation }}
      databaseRegionInformation: ${{ steps.regions.outputs.databaseRegionInformation }}
      imageBuilderRegionInformation: ${{ steps.regions.outputs.imageBuilderRegionInformation }}
      defaultRegion: ${{ steps.regions.outputs.defaultRegion }}
      secrets: ${{ steps.secrets.outputs.secrets }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Install JQ utility
        run: sudo apt-get install jq

      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            cat "$f" >> "$GITHUB_ENV"
          done

      - name: Dump workflow env context
        run: echo '${{ toJson(env) }}'

      - name: Validate required identifiers
        run: |
          accountName="$(echo -n "${accountName:-${{ (env.accountName || inputs.accountName) }}}" | xargs)"
          subnetIdentifier="$(echo -n "${subnetIdentifier:-${{ (env.subnetIdentifier || inputs.subnetIdentifier) }}}" | xargs)"
          regions="$(echo -n "${regions:-${{ (env.regions || inputs.regions) }}}" | xargs)"
          environment="$(echo -n "${environment:-${{ (env.environment || inputs.environment) }}}" | xargs)"
          minimumRunningInstances="$(echo -n "${minimumRunningInstances:-${{ (env.minimumRunningInstances || inputs.minimumRunningInstances) }}}" | xargs)"
          desiredInstanceCapacity="$(echo -n "${desiredInstanceCapacity:-${{ (env.desiredInstanceCapacity || inputs.desiredInstanceCapacity) }}}" | xargs)"
          maximumRunningInstances="$(echo -n "${maximumRunningInstances:-${{ (env.maximumRunningInstances || inputs.maximumRunningInstances) }}}" | xargs)"
          if [ -z "$accountName" ] || [ -z "$subnetIdentifier" ]; then
            echo "accountName and subnetIdentifier must be provided via vars artifact or inputs" >&2
            exit 1
          fi
          if [ -z "$regions" ]; then
            echo "regions must be provided via vars artifact or inputs" >&2
            exit 1
          fi
          if [ -z "$environment" ]; then
            echo "environment must be provided via vars artifact or inputs" >&2
            exit 1
          fi
          if [ -z "$minimumRunningInstances" ]; then
            echo "minimumRunningInstances must be provided via vars artifact or inputs" >&2
            exit 1
          fi
          if [ -z "$desiredInstanceCapacity" ]; then
            echo "desiredInstanceCapacity must be provided via vars artifact or inputs" >&2
            exit 1
          fi
          if [ -z "$maximumRunningInstances" ]; then
            echo "maximumRunningInstances must be provided via vars artifact or inputs" >&2
            exit 1
          fi

      - name: Fetch all tags
        run: git fetch --all --tags

      - name: Validate inputs and process payload
        run: |
          if [ -n "${{ (env.secretPayloadEncrypted || inputs.secretPayloadEncrypted) }}" ]; then
            if [ -z "${{ secrets.ENCRYPTION_KEY }}" ]; then
              echo "::error::inputs.secretPayloadEncrypted is set but secrets.ENCRYPTION_KEY is missing."
              exit 1
            fi
          elif [ -n "${{ secrets.ENCRYPTION_KEY }}" ]; then
            echo "::warning::secrets.ENCRYPTION_KEY is set but inputs.secretPayloadEncrypted is not provided."
          fi

      - name: Account / Environment / Auto Scaling Variables
        id: account
        run: |
          echo "repo=${GITHUB_REPOSITORY##*/}" >> $GITHUB_OUTPUT
          echo "ref=${GITHUB_REF}" >> $GITHUB_OUTPUT
          DEFAULT_GIT_BRANCH=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@')
          echo "default_branch=${DEFAULT_GIT_BRANCH}" >> $GITHUB_OUTPUT
          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
          echo "currentBranch=${CURRENT_BRANCH}" >> $GITHUB_OUTPUT
          REPO_NAME="${GITHUB_REPOSITORY##*/}"
          echo "repository=${REPO_NAME}" >> $GITHUB_OUTPUT
          echo "repositoryNicename=${REPO_NAME//./-}" >> $GITHUB_OUTPUT
          if [ -z "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}" ] || [ -z "${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }}" ]; then
            echo "Error: instanceDeploymentAccountOidcRole and networkAccountOidcRole must be provided."
            exit 1
          fi
          DEPLOYMENT_ACCOUNT_ID=$( echo "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}" | cut -d':' -f5 )
          NETWORK_ACCOUNT_ID=$( echo "${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }}" | cut -d':' -f5 )
          echo "deploymentAccountId=${DEPLOYMENT_ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "networkingAccountId=${NETWORK_ACCOUNT_ID}" >> $GITHUB_OUTPUT

      - name: Set AWS Subnet Blocks
        id: network
        run: |
          set -eEBx
          chmod +x ./.github/assets/shell/setSubnets.sh
          ./.github/assets/shell/setSubnets.sh \
            "${{ (env.subnetIdentifier || inputs.subnetIdentifier) }}" \
            "${{ (env.highlyAvailableNat || inputs.highlyAvailableNat) }}" \
            "${{ (env.enableVpcFlowLogs || inputs.enableVpcFlowLogs) }}" \
            "$GITHUB_OUTPUT"

      - name: Process Regions
        id: regions
        run: |
          REGIONS=(${{ (env.regions || inputs.regions) }})

          # Set DEFAULT_REGION to the first region in regions if defaultRegion is not provided
          if [ -z "${{ (env.defaultRegion || inputs.defaultRegion) }}" ]; then
            DEFAULT_REGION="${REGIONS[0]}"
          else
            DEFAULT_REGION="${{ (env.defaultRegion || inputs.defaultRegion) }}"
          fi

          # Set DATABASE_REGIONS to defaultRegion if databaseRegions is not provided
          if [ -z "${{ (env.databaseRegions || inputs.databaseRegions) }}" ]; then
            DATABASE_REGIONS=($DEFAULT_REGION)
          else
            DATABASE_REGIONS=(${{ (env.databaseRegions || inputs.databaseRegions) }})
          fi

          if [ -z "${{ (env.imageBuilderRegions || inputs.imageBuilderRegions) }}" ]; then
            IMAGE_BUILDER_REGIONS=($DEFAULT_REGION)
          else
            IMAGE_BUILDER_REGIONS=(${{ (env.imageBuilderRegions || inputs.imageBuilderRegions) }})
          fi

          REGION_MATRIX=$(jq -n --arg regions "${{ (env.regions || inputs.regions) }}" '{"aws-region": ($regions | split(","))}')
          DATABASE_REGION_MATRIX=$(jq -n --arg regions "$(echo "${DATABASE_REGIONS[*]}" | tr ' ' ',')" '{"aws-region": ($regions | split(","))}')
          IMAGE_BUILDER_REGIONS_MATRIX=$(jq -n --arg regions "$(echo "${IMAGE_BUILDER_REGIONS[*]}" | tr ' ' ',')" '{"aws-region": ($regions | split(","))}')

          echo "regionInformation=$(echo $REGION_MATRIX | jq -c)" >> $GITHUB_OUTPUT
          echo "defaultRegion='${DEFAULT_REGION}'" >> $GITHUB_OUTPUT
          echo "databaseRegionInformation=$(echo $DATABASE_REGION_MATRIX | jq -c)" >> $GITHUB_OUTPUT
          echo "imageBuilderRegionInformation=$(echo $IMAGE_BUILDER_REGIONS_MATRIX | jq -c)" >> $GITHUB_OUTPUT

          echo "DEFAULT_REGION: ${DEFAULT_REGION}"
          echo "REGION_MATRIX: ${REGION_MATRIX}"
          echo "DATABASE_REGION_MATRIX: ${DATABASE_REGION_MATRIX}"
          echo "IMAGE_BUILDER_REGIONS_MATRIX: ${IMAGE_BUILDER_REGIONS_MATRIX}"

  SHARED-NETWORKING:
    outputs:
      vpc: ${{ steps.export-vpc.outputs.vpc }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: CONSTANTS
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Configure AWS credentials for Shared Networking Account (${{ needs.CONSTANTS.outputs.networkingAccountId }}) (${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Deploy VPC stack
        run: |
          if ! aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ (env.accountName || inputs.accountName) }}-network; then
            ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} ${{ (env.accountName || inputs.accountName) }}-network \
              --template-body file://CloudFormation/vpc.yaml \
              --parameters \
                ParameterKey=VpcCidrParam,ParameterValue="${{ needs.CONSTANTS.outputs.vpcCidrParam }}"  \
                ParameterKey=PrivateAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZASubnetBlock }}"  \
                ParameterKey=PublicAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZASubnetBlock }}"  \
                ParameterKey=DataAZASubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZASubnetBlock }}"  \
                ParameterKey=PrivateAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZBSubnetBlock }}"  \
                ParameterKey=PublicAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZBSubnetBlock }}"  \
                ParameterKey=DataAZBSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZBSubnetBlock }}"  \
                ParameterKey=PrivateAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.privateAZCSubnetBlock }}"  \
                ParameterKey=PublicAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.publicAZCSubnetBlock }}"  \
                ParameterKey=DataAZCSubnetBlock,ParameterValue="${{ needs.CONSTANTS.outputs.dataAZCSubnetBlock }}"  \
                ParameterKey=HighlyAvailableNat,ParameterValue="${{ needs.CONSTANTS.outputs.highlyAvailableNat }}"  \
                ParameterKey=EnableVpcFlowLogs,ParameterValue="${{ needs.CONSTANTS.outputs.enableVpcFlowLogs }}"
          
            echo "Sleeping for 240 seconds to allow VPC stack exports to propagate. We've seen timing issues with the VPC stack exports not being available immediately for networkshares."
            sleep 240
          
          else
            echo "The VPC stack already exists on the AWS network account."
          fi

      - name: Sharing VPC network from (${{ needs.CONSTANTS.outputs.networkingAccountId }}) to (${{ needs.CONSTANTS.outputs.deploymentAccountId }})
        run: |
          if ! aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ (env.accountName || inputs.accountName) }}-networkshares; then
            ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} ${{ (env.accountName || inputs.accountName) }}-networkshares \
                    --template-body file://./CloudFormation/network.yaml \
                    --parameters \
                      ParameterKey=NetworkStackName,ParameterValue="${{ (env.accountName || inputs.accountName) }}-network" \
                      ParameterKey=Environment,ParameterValue="${{ (env.environment || inputs.environment) }}" \
                      ParameterKey=AccountId,ParameterValue="${{ needs.CONSTANTS.outputs.deploymentAccountId }}"
          fi

      - name: Export VPC ID
        id: export-vpc
        run: |
          VPC_ID=$(aws cloudformation describe-stacks --region ${{ matrix.aws-region }} --stack-name ${{ (env.accountName || inputs.accountName) }}-network --query 'Stacks[0].Outputs[?OutputKey==`VpcId`].OutputValue' --output text)
          echo "vpc=${VPC_ID}" >> $GITHUB_OUTPUT

  REGIONAL-NETWORKING:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, SHARED-NETWORKING ]
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Get AWS Subnet IDs
        run: |
          
          set -eEBx
          
          # dont use source here so variable usage is explicit
          chmod +x ./.github/assets/shell/getSubnets.sh
          
          ./.github/assets/shell/getSubnets.sh \
            "${{ needs.SHARED-NETWORKING.outputs.vpc }}" \
            "${{ matrix.aws-region }}" \
            "${{ needs.CONSTANTS.outputs.deploymentAccountId }}" \
            "${{ needs.CONSTANTS.outputs.privateAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZASubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.privateAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZBSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.privateAZCSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.publicAZCSubnetBlock }}" \
            "${{ needs.CONSTANTS.outputs.dataAZCSubnetBlock }}" \
            "$GITHUB_ENV"

      - name: aws stack iam
        if: ${{ matrix.aws-region == 'us-east-1' }}
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} iam \
          --template-body file://./CloudFormation/iam.yaml \
          --capabilities CAPABILITY_NAMED_IAM

      - name: aws stack sg
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} sg \
          --template-body file://./CloudFormation/sg.yaml \
          --parameters \
          ParameterKey=VpcId,ParameterValue="\"${{ env.vpc }}\""

      - name: aws ec2 get security group
        run: |
          SECURITY_GROUP="$( aws ec2 describe-security-groups --query 'SecurityGroups[].GroupId' --filters Name=group-name,Values=\*Ec2\* --output text )"
          if [[ "" != "$SECURITY_GROUP" ]]; then
            echo "The Ec2 security group was found."
          else
            echo "No Ec2 security group was found. The Security group is created in sg.yaml"
            exit 1;
          fi
          echo "security=$SECURITY_GROUP" >> REGIONAL-NETWORKING.txt

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "REGIONAL-NETWORKING.sh"
          done < "REGIONAL-NETWORKING.txt"
          cat REGIONAL-NETWORKING.sh

      - name: Upload subnet IDs artifact
        uses: actions/upload-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./REGIONAL-NETWORKING.sh

  ACM-AND-ROUTE-53:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS ]  # Ensure it runs after constant setup
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install jq

      - name: Set up AWS credentials for the deployment account
        if: ${{ (env.domains || inputs.domains) != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: "github-actions-oidc-session"
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Run ACM and Route 53 Update Script
        id: certificates-and-cnames
        if: ${{ (env.domains || inputs.domains) != '' }}
        run: |
          
          # Pass the domains you want to manage as input, e.g. example.com,www.example.com
          source ./.github/assets/shell/getAmazonCertificateManagerSSL.sh "${{ (env.domains || inputs.domains) }}"

      - name: Authenticate to Shared Networking Account
        if: ${{ (env.domains || inputs.domains) != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }}"
          role-session-name: "github-actions-oidc-session"
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Update DNS validation CNAME records
        run: |
          set -eEBx
          
          # Split the comma-separated entries into an array
          IFS=',' read -ra entries <<< "${{ env.domains_with_cname }}"
          # Loop through each domain=CNAME:VALUE entry
          for entry in "${entries[@]}"; do
            domain="${entry%%=*}"
            cname_value="${entry#*=}"
            cname="${cname_value%%:*}"
            value="${cname_value#*:}"
            echo "Applying CNAME validation record for $domain: $cname -> $value"
            source ./.github/assets/shell/updateRoute53.sh "$domain" "$cname" "$value"
          done
        shell: bash

      - name: Set up AWS credentials for the deployment account
        if: ${{ (env.domains || inputs.domains) != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: "github-actions-oidc-session"
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Wait for ACM certificates to be validated
        if: ${{ (env.domains || inputs.domains) != '' && env.domains_with_cname != '' }}
        run: |
          set -eEBx
          
          IFS=',' read -ra CERTIFICATES_ARRAY <<< "${{ env.certificates }}"
          IFS=',' read -ra CNAME_ENTRIES <<< "${{ env.domains_with_cname }}"
          
          for cert in "${CERTIFICATES_ARRAY[@]}"; do
            cert=$(echo "$cert" | xargs)
        
            # Match cert to domain (based on order — assumes consistent ordering!)
            cname_entry="${CNAME_ENTRIES[0]}"
            CNAME_ENTRIES=("${CNAME_ENTRIES[@]:1}")
          
            domain="${cname_entry%%=*}"
            cname_value="${cname_entry#*=}"
            CNAME="${cname_value%%:*}"
        
            echo "Waiting for certificate to be validated for $domain ($cert)"
          
            timeout=300  # seconds
            interval=10  # seconds
            elapsed=0
            
            while ! dig +short "$CNAME" >/dev/null; do
              if (( elapsed >= timeout )); then
                echo "❌ Timeout waiting for DNS propagation of $CNAME after $timeout seconds."
                exit 1
              fi
              echo "⏳ Waiting for DNS propagation of $CNAME... ($elapsed/$timeout)"
              sleep "$interval"
              (( elapsed += interval ))
            done
        
            # Wait for ACM to validate
            AWS_MAX_ATTEMPTS=100 aws acm wait certificate-validated --certificate-arn "$cert"
          done
        shell: bash

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "CERTIFICATES.sh"
          done < "CERTIFICATES.txt"
          cat CERTIFICATES.sh

      - name: Upload certificate IDs artifact
        uses: actions/upload-artifact@v4
        with:
          name: CERTIFICATES-${{ matrix.aws-region }}
          path: ./CERTIFICATES.sh


  # New job to ensure ECR repository exists and set up EKS if needed
  LOAD-BALANCERS:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, REGIONAL-NETWORKING, ACM-AND-ROUTE-53 ]
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Download Certificates artifact
        uses: actions/download-artifact@v4
        with:
          name: CERTIFICATES-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh   
          cat CERTIFICATES.sh
          source ./CERTIFICATES.sh   

      - name: Deploy ALB stack
        if: ${{ (env.deployALB || inputs.deployALB) == 'true' }}
        run: |
          set -eEBx
          FIRST_CERT=$(echo "${{ env.certificates }}" | cut -d',' -f1)
          php "./.github/assets/php/createAlbYaml.php" "$FIRST_CERT" > ./CloudFormation/alb.yaml
          cat ./CloudFormation/alb.yaml
          sleep 3
          ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} alb \
            --template-body file://./CloudFormation/alb.yaml \
            --parameters 'ParameterKey=PublicSubnets,ParameterValue="${{ env.publicSubnet }}"'

      - name: Deploy NLB stack
        if: ${{ (env.deployNLB || inputs.deployNLB) == 'true' }}
        run: ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} nlb \
          --template-body file://./CloudFormation/nlb.yaml \
          --parameters  \
          ParameterKey=VpcId,ParameterValue="${{ env.vpc }}" \
          ParameterKey=PublicSubnets,ParameterValue="${{ env.publicAZASubnet }}"

      - name: Capture load balancer DNS
        if: ${{ (env.domains || inputs.domains) != '' }}
        run: |
          set -eEBx
          if aws cloudformation describe-stacks --stack-name nlb >/dev/null 2>&1; then
            LB_DNS=$(aws cloudformation describe-stacks --stack-name nlb --query "Stacks[0].Outputs[?OutputKey=='PublicNlbDnsName'].OutputValue" --output text)
            LB_ZONE=$(aws cloudformation describe-stacks --stack-name nlb --query "Stacks[0].Outputs[?OutputKey=='PublicNlbCanonicalHostedZoneId'].OutputValue" --output text)
          else
            LB_DNS=$(aws cloudformation describe-stacks --stack-name alb --query "Stacks[0].Outputs[?OutputKey=='PublicAlbDnsName'].OutputValue" --output text)
            LB_ZONE=$(aws cloudformation describe-stacks --stack-name alb --query "Stacks[0].Outputs[?OutputKey=='PublicAlbCanonicalHostedZoneId'].OutputValue" --output text)
          fi
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "LB_ZONE=$LB_ZONE" >> $GITHUB_ENV

      - name: Authenticate to Shared Networking Account for DNS
        if: ${{ (env.domains || inputs.domains) != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.networkAccountOidcRole || inputs.networkAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Upsert Route53 alias
        if: ${{ (env.domains || inputs.domains) != '' }}
        run: |
          set -eEBx
          IFS=',' read -ra DOMAINS <<< "${{ (env.domains || inputs.domains) }}"
          for domain in "${DOMAINS[@]}"; do
            ./.github/assets/shell/updateRoute53Alias.sh "$domain" "$LB_DNS" "$LB_ZONE"
          done

      # It is possible for no variables to be in this file, so we touch it first
      - name: Create ENV variables
        run: |
          touch LOAD-BALANCERS.txt
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "LOAD-BALANCERS.sh"
          done < "LOAD-BALANCERS.txt"
          touch LOAD-BALANCERS.sh
          cat LOAD-BALANCERS.sh

      - name: Upload load balancer artifact
        uses: actions/upload-artifact@v4
        with:
          name: LOAD-BALANCERS-${{ matrix.aws-region }}
          path: ./LOAD-BALANCERS.sh

  DATABASE:
    if: ${{ needs.FLAGS.outputs.deployDatabase == 'true' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.databaseRegionInformation) }}
    runs-on: ubuntu-latest
    needs: [ FLAGS, CONSTANTS, REGIONAL-NETWORKING ]
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          source ./REGIONAL-NETWORKING.sh
          cat REGIONAL-NETWORKING.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Deploy AWS RDS (database) stack
        run: |
          # Determine the subnet to use based on the input
          if [ "${{ (env.databasePubliclyAccessible || inputs.databasePubliclyAccessible) }}" = "true" ]; then
            DATA_SUBNET="${{ env.publicSubnet }}"
          else
            DATA_SUBNET="${{ env.dataSubnet }}"
          fi
          echo "Using subnet: $DATA_SUBNET"
          
          # Run the CloudFormation script
          ./.github/assets/shell/createUpdateCFStack.sh ${{ matrix.aws-region }} ${{ (env.databaseEngine || inputs.databaseEngine) && format('{0}-rds-database', (env.databaseEngine || inputs.databaseEngine)) || 'rds-database' }} \
          --template-body file://./CloudFormation/database.yaml \
          --parameters \
            ParameterKey=VpcCidr,ParameterValue="${{ needs.CONSTANTS.outputs.vpcCidrParam }}" \
            ParameterKey=VpcId,ParameterValue="${{ env.vpc }}" \
            "ParameterKey=DataSubnets,ParameterValue=\"$DATA_SUBNET\"" \
            ParameterKey=DatabaseEngine,ParameterValue="${{ (env.databaseEngine || inputs.databaseEngine) }}" \
            ParameterKey=DatabaseEngineVersion,ParameterValue="${{ (env.databaseEngineVersion || inputs.databaseEngineVersion) }}" \
            ParameterKey=ServerlessVersion,ParameterValue="${{ (env.databaseServerlessVersion || inputs.databaseServerlessVersion) }}" \
            ParameterKey=DatabaseInstanceType,ParameterValue="${{ (env.databaseInstanceType || inputs.databaseInstanceType) }}" \
            ParameterKey=DatabaseMasterUsername,ParameterValue="${{ (env.databaseMasterUsername || inputs.databaseMasterUsername) }}" \
            ParameterKey=DatabaseMasterPassword,ParameterValue="${{ (env.databaseMasterPassword || inputs.databaseMasterPassword) }}" \
            ParameterKey=DatabaseName,ParameterValue="${{ (env.databaseName || inputs.databaseName) }}" \
            ParameterKey=InstanceIdentifierPrefix,ParameterValue="${{ (env.databaseInstanceIdentifierPrefix || inputs.databaseInstanceIdentifierPrefix) }}" \
            ParameterKey=MultiAZ,ParameterValue="${{ (env.databaseMultiAZ || inputs.databaseMultiAZ) }}" \
            ParameterKey=PubliclyAccessible,ParameterValue="${{ (env.databasePubliclyAccessible || inputs.databasePubliclyAccessible) }}" \
            ParameterKey=AllocatedStorage,ParameterValue="${{ (env.databaseAllocatedStorage || inputs.databaseAllocatedStorage) }}" \
            ParameterKey=BackupRetentionPeriod,ParameterValue="${{ (env.databaseBackupRetentionPeriod || inputs.databaseBackupRetentionPeriod) }}" \
            ParameterKey=StorageType,ParameterValue="${{ (env.databaseStorageType || inputs.databaseStorageType) }}" \
            ParameterKey=DeletionProtection,ParameterValue="${{ (env.databaseDeletionProtection || inputs.databaseDeletionProtection) }}" \
            ParameterKey=PreferredBackupWindow,ParameterValue="${{ (env.databasePreferredBackupWindow || inputs.databasePreferredBackupWindow) }}" \
            ParameterKey=PreferredMaintenanceWindow,ParameterValue="${{ (env.databasePreferredMaintenanceWindow || inputs.databasePreferredMaintenanceWindow) }}" \
            ParameterKey=StorageEncrypted,ParameterValue="${{ (env.databaseStorageEncrypted || inputs.databaseStorageEncrypted) }}" \
            ParameterKey=ScalingConfigurationMinCapacity,ParameterValue="${{ (env.databaseScalingConfigurationMinCapacity || inputs.databaseScalingConfigurationMinCapacity) }}" \
            ParameterKey=ScalingConfigurationMaxCapacity,ParameterValue="${{ (env.databaseScalingConfigurationMaxCapacity || inputs.databaseScalingConfigurationMaxCapacity) }}"

          # Fetch the Aurora security group
          AURORA_SECURITY_GROUP=$(aws ec2 describe-security-groups --query 'SecurityGroups[].GroupId' --filters Name=group-name,Values=*rds* --output text | tr -d '\r')
          
          # Check if the security group was found
          if [[ -z "$AURORA_SECURITY_GROUP" ]]; then
            echo "Error: No Aurora security group was found. The security group should be created automatically by the Aurora cluster."
            exit 1
          fi
          
          echo "Aurora Security Group: $AURORA_SECURITY_GROUP"
          
          # Output the security group ID
          echo "rds-security=$AURORA_SECURITY_GROUP" >> DATABASE.txt

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "DATABASE.sh"
          done < "DATABASE.txt"
          cat DATABASE.sh

      - name: Upload RDS security group artifact
        uses: actions/upload-artifact@v4
        with:
          name: DATABASE-${{ matrix.aws-region }}
          path: ./DATABASE.sh

  DOCKER-CONTAINER:
    if: ${{ needs.FLAGS.outputs.dockerBuildConfig != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    needs: [ FLAGS, CONSTANTS ]
    runs-on: ubuntu-latest
    env:
      IMAGE_TAG: ${{ github.sha }}
    outputs:
      ecr_uri: ${{ steps.ecr-login.outputs.ecr_uri }}
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker Image
        run: |
          CONFIG="${{ (env.dockerBuildConfig || inputs.dockerBuildConfig) }}"
          echo "Building image from: $CONFIG"
          
          if [[ "$CONFIG" == "true" || "$CONFIG" == "Dockerfile" ]]; then
            echo "Using default Dockerfile"
            docker build -t ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}:$IMAGE_TAG .
          elif [[ "$CONFIG" == *".yml" || "$CONFIG" == *".yaml" ]]; then
            echo "Using Compose file: $CONFIG"
            docker compose -f "$CONFIG" build
            docker tag ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}_web ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}:$IMAGE_TAG  # change ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}_web to your service
          elif [[ "$CONFIG" == *"Dockerfile"* ]]; then
            echo "Using custom Dockerfile: $CONFIG"
            docker build -f "$CONFIG" -t ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}:$IMAGE_TAG .
          else
            echo "Unsupported dockerBuildConfig value: $CONFIG"
            exit 1
          fi

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Login to Amazon ECR manually and set ECR_URI
        id: ecr-login
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          REGION=${{ matrix.aws-region }}
          REPO=${{ (env.ecrRepository || inputs.ecrRepository) }}
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/${REPO}"
          
          echo "Logging into ECR: $ECR_URI"
          aws ecr get-login-password --region "$REGION" | docker login --username AWS --password-stdin "${AWS_ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com"
          
          echo "ecr_uri=$ECR_URI" >> $GITHUB_OUTPUT

      - name: Create ECR Repository if not exists
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          REGION=${{ matrix.aws-region }}
          REPO=${{ (env.ecrRepository || inputs.ecrRepository) }}
          ECR_URI="${AWS_ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/${REPO}"
          
          # Check if the ECR repository exists
          echo "Checking if ECR repository exists: $REPO"
          if ! aws ecr describe-repositories --repository-name "$REPO" --region "$REGION" > /dev/null 2>&1; then
            echo "Repository does not exist. Creating repository: $REPO"
            aws ecr create-repository --repository-name "$REPO" --region "$REGION"
          else
            echo "Repository already exists: $REPO"
          fi

      - name: Tag and Push Docker Image to ECR
        run: |
          docker tag ${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}:$IMAGE_TAG ${{ steps.ecr-login.outputs.ecr_uri }}:$IMAGE_TAG
          docker push ${{ steps.ecr-login.outputs.ecr_uri }}:$IMAGE_TAG



  DEPLOY-ECR-K8S:
    if: ${{ needs.FLAGS.outputs.ecrRepository != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.imageBuilderRegionInformation) }}
    runs-on: ubuntu-latest
    needs: [ FLAGS, CONSTANTS, DOCKER-CONTAINER, SHARED-NETWORKING, REGIONAL-NETWORKING, DATABASE, ACM-AND-ROUTE-53 ]
    outputs:
      ecrRepoUri: ${{ steps.ecr.outputs.ecrRepoUri }}
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials for ECR setup
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh   

      - name: Create EKS cluster (if not exists)
        if: ${{ (env.eksClusterName || inputs.eksClusterName) != '' }}
        run: |
          set -eEuxo pipefail

          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin

          if eksctl get cluster --name "${{ (env.eksClusterName || inputs.eksClusterName) }}" --region "${{ matrix.aws-region }}"; then
            echo "Cluster '${{ (env.eksClusterName || inputs.eksClusterName) }}' already exists. Skipping creation."
          else
            eksctl create cluster \
              --name "${{ (env.eksClusterName || inputs.eksClusterName) }}" \
              --version "${{ (env.eksClusterVersion || inputs.eksClusterVersion) }}" \
              --region "${{ matrix.aws-region }}" \
              --vpc-public-subnets "${{ env.publicAZASubnet }},${{ env.publicAZBSubnet }},${{ env.publicAZCSubnet }}" \
              --vpc-private-subnets "${{ env.privateAZASubnet }},${{ env.privateAZBSubnet }},${{ env.privateAZCSubnet }},${{ env.dataAZASubnet }},${{ env.dataAZBSubnet }},${{ env.dataAZCSubnet }}" \
              --without-nodegroup \
              --with-oidc \
              --asg-access \
              --full-ecr-access
          fi

      - name: Wait for cluster to become ACTIVE
        run: |
          set -eEuo pipefail
          CLUSTER="${{ (env.eksClusterName || inputs.eksClusterName) }}"
          REGION="${{ matrix.aws-region }}"

          echo "Waiting for EKS cluster '$CLUSTER' to become ACTIVE in $REGION..."
          for i in {1..30}; do
            STATUS=$(aws eks describe-cluster --region "$REGION" --name "$CLUSTER" --query "cluster.status" --output text)
            echo "Cluster status: $STATUS"
            if [[ "$STATUS" == "ACTIVE" ]]; then
              echo "✅ Cluster is ACTIVE"
              break
            fi
            if [[ "$STATUS" == "FAILED" ]]; then
              echo "❌ Cluster failed to become active"
              exit 1
            fi
            sleep 30
          done

      - name: Add new node group
        run: |
          set -eEuxo pipefail

          NEW_NODEGROUP_NAME="ng-${{ (env.eksClusterName || inputs.eksClusterName) }}-${{ github.run_number }}"
          CLUSTER_NAME="${{ (env.eksClusterName || inputs.eksClusterName) }}"
          REGION="${{ matrix.aws-region }}"

          echo "Creating new nodegroup: $NEW_NODEGROUP_NAME"

          eksctl create nodegroup \
            --cluster "$CLUSTER_NAME" \
            --name "$NEW_NODEGROUP_NAME" \
            --region "$REGION" \
            --node-type "${{ (env.instanceType || inputs.instanceType) }}" \
            --nodes "${{ (env.desiredInstanceCapacity || inputs.desiredInstanceCapacity) }}" \
            --nodes-min "${{ (env.minimumRunningInstances || inputs.minimumRunningInstances) }}" \
            --nodes-max "${{ (env.maximumRunningInstances || inputs.maximumRunningInstances) }}" \
            --managed \
            --node-ami-family "AmazonLinux2" \
            --ssh-access=false || {
              echo "❌ Failed to create node group. Fetching CloudFormation stack events..."
              STACK_NAME="eksctl-${CLUSTER_NAME}-nodegroup-${NEW_NODEGROUP_NAME}"
              aws cloudformation describe-stack-events --region "$REGION" --stack-name "$STACK_NAME" | head -n 30
              exit 1
          }

          aws eks wait nodegroup-active \
            --cluster-name "$CLUSTER_NAME" \
            --nodegroup-name "$NEW_NODEGROUP_NAME" \
            --region "$REGION"

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --region "${{ matrix.aws-region }}" --name "${{ (env.eksClusterName || inputs.eksClusterName) }}"

      - name: Deploy to Kubernetes (combined manifest)
        run: |
          set -eEuxo pipefail
          
          IMAGE_URI="${{ needs.DOCKER-CONTAINER.outputs.ecr_uri }}:${{ github.sha }}"
          echo "Deploying image: $IMAGE_URI"
          
          sed "s|<REPLACEME_WITH_IMAGE>|$IMAGE_URI|g" "${{ (env.k8sDeploymentManifestPath || inputs.k8sDeploymentManifestPath) }}" > rendered-deployment.yaml
          
          kubectl apply -f rendered-deployment.yaml
          kubectl rollout status deployment/${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}
          kubectl get svc,deploy,pods -o wide

      - name: Health Check Post-Deploy
        run: |
          kubectl rollout status deployment/${{ (env.k8sDeploymentName || inputs.k8sDeploymentName) }}
          kubectl get pods -o wide

      - name: Delete old node group(s)
        run: |
          set -eEuxo pipefail

          CLUSTER_NAME="${{ (env.eksClusterName || inputs.eksClusterName) }}"
          REGION="${{ matrix.aws-region }}"
          NEW_NODEGROUP_NAME="ng-${CLUSTER_NAME}-${{ github.run_number }}"

          EXISTING_GROUPS=$(eksctl get nodegroup --cluster "$CLUSTER_NAME" --region "$REGION" -o json | jq -r ".[] | select(.Name | startswith(\"ng-${CLUSTER_NAME}-\")) | .Name")

          for NODEGROUP in $EXISTING_GROUPS; do
            if [[ "$NODEGROUP" != "$NEW_NODEGROUP_NAME" ]]; then
              echo "Deleting old nodegroup: $NODEGROUP"
              eksctl delete nodegroup \
                --cluster "$CLUSTER_NAME" \
                --region "$REGION" \
                --name "$NODEGROUP"
            else
              echo "Keeping new nodegroup: $NODEGROUP"
            fi
          done

  IMAGE-BUILDER:
    if: ${{ needs.FLAGS.outputs.imageBuilderScriptBuild != '' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.imageBuilderRegionInformation) }}
    runs-on: ubuntu-latest
    needs: [ FLAGS, CONSTANTS, REGIONAL-NETWORKING ]
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download subnet IDs artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat ./REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Get or create infrastructure configuration
        run: |
          
          set -eEBx
          
          # Determine the instance types to use
          if [ -z "${{ (env.imageBuilderInstanceTypes || inputs.imageBuilderInstanceTypes) }}" ]; then
            INSTANCE_TYPES=${{ (env.instanceType || inputs.instanceType) }}
          else
            INSTANCE_TYPES="${{ (env.imageBuilderInstanceTypes || inputs.imageBuilderInstanceTypes) }}"
          fi
          
          INFRASTRUCTURE_ARGUMENTS=(
            --instance-profile-name EC2RoleForImageBuilder 
            --subnet-id $publicAZASubnet 
            --instance-types $INSTANCE_TYPES
            --security-group-ids ${{ env.security }}  ${{ env.rds-security }} 
          )
          
          EXISTING_INFRA_CONFIG=$(aws imagebuilder list-infrastructure-configurations \
          --filter name=name,values=development-infrastructure-configuration \
          --query 'infrastructureConfigurationSummaryList[?name==`development-infrastructure-configuration`].arn' \
          --output text)
          
          if [[ -z "$EXISTING_INFRA_CONFIG" ]]; then
          aws imagebuilder create-infrastructure-configuration "${INFRASTRUCTURE_ARGUMENTS[@]}" \
          --name development-infrastructure-configuration
          else
            echo "Infrastructure configuration already exists: $EXISTING_INFRA_CONFIG"
          fi
          
          ARN=$(aws imagebuilder list-infrastructure-configurations \
            --filter name=name,values=development-infrastructure-configuration \
            --query 'infrastructureConfigurationSummaryList[?name==`development-infrastructure-configuration`].arn' \
            --output text)

          aws imagebuilder update-infrastructure-configuration --infrastructure-configuration-arn "$ARN" "${INFRASTRUCTURE_ARGUMENTS[@]}"

          echo "infrastructure=$ARN" >> $GITHUB_ENV
          echo "infrastructure=$ARN" >> $GITHUB_OUTPUT


      - name: Dynamic Region
        id: region
        run: |
          
          # Convert the regions array to a JSON array
          php  "./.github/assets/php/createAmiDistribution.php" "${{ needs.CONSTANTS.outputs.deploymentAccountId }}" "${{ needs.CONSTANTS.outputs.networkingAccountId }}" '${{ needs.CONSTANTS.outputs.imageBuilderRegionInformation }}' > amiDistribution.json 
          
          echo "AMI Distribution JSON:"
          cat amiDistribution.json

          # Check if the file was created successfully
          if [ $? -ne 0 ]; then
            exit 97
          fi

          # Print the filename on success - this works as it is only used locally in this job
          # dynamic files will be destroyed after any job is done
          echo "name=amiDistribution.json" >> $GITHUB_ENV
          echo "name=amiDistribution.json" >> $GITHUB_OUTPUT

      - name: Create or update distribution configuration
        id: distribution
        run: |
          
          set -eEBx
          
          DYNAMIC_REGION="${{ steps.region.outputs.name }}"

          DISTRIBUTION_ARGUMENTS=(
            --cli-input-json "file://$DYNAMIC_REGION"
          )

          DISTRIBUTIONS=$(aws imagebuilder list-distribution-configurations \
                            --filter 'name=name,values=${{ (env.accountName || inputs.accountName) }}-distribution-configuration' \
                            --query 'distributionConfigurationSummaryList[-1].arn' --output text | grep "${{ (env.accountName || inputs.accountName) }}" || echo "")

          if [[ -z "$DISTRIBUTIONS" ]]
          then
            aws imagebuilder create-distribution-configuration \
                        --name ${{ (env.accountName || inputs.accountName) }}-distribution-configuration \
                        "${DISTRIBUTION_ARGUMENTS[@]}"
            sleep 240
          else
            aws imagebuilder update-distribution-configuration \
                    --distribution-configuration-arn \
                        $(aws imagebuilder list-distribution-configurations --output text \
                                  --query 'distributionConfigurationSummaryList[-1].arn') \
                    "${DISTRIBUTION_ARGUMENTS[@]}"
          fi

          EXPORT_DISTRIBUTION=$(aws imagebuilder list-distribution-configurations \
                            --filter 'name=name,values=${{ (env.accountName || inputs.accountName) }}-distribution-configuration' \
                            --query 'distributionConfigurationSummaryList[-1].arn' --output text | grep "${{ (env.accountName || inputs.accountName) }}")

          echo "distribution=$EXPORT_DISTRIBUTION" >> $GITHUB_ENV
          echo "distribution=$EXPORT_DISTRIBUTION" >> IMAGE-BUILDER.txt

      - name: Create or update image builder
        id: imageBuilder
        run: |
          
          shopt -s failglob
          set -eEBxuo pipefail
          
          cat > ./imageBuilderScriptBuild <<'IMAGE-BUILDER-BUILD-EOF'
          ${{ (env.imageBuilderScriptBuild || inputs.imageBuilderScriptBuild) }}
          IMAGE-BUILDER-BUILD-EOF
          
          cat > ./imageBuilderScriptValidate <<'IMAGE-BUILDER-VALIDATE-EOF'
          ${{ (env.imageBuilderScriptValidate || inputs.imageBuilderScriptValidate) }}
          IMAGE-BUILDER-VALIDATE-EOF
          
          chmod +x ./.github/assets/shell/createUpdateImageBuilder.sh
          ./.github/assets/shell/createUpdateImageBuilder.sh \
            "${{ env.distribution }}" \
            "${{ matrix.aws-region }}" \
            "${{ (env.environment || inputs.environment) }}" \
            "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
            "${{ secrets.ENCRYPTION_KEY }}" \
            "${{ (env.secretPayloadEncrypted || inputs.secretPayloadEncrypted) }}" \
            "${{ (env.imageBuilderBaseImageAMI || inputs.imageBuilderBaseImageAMI) }}" \
            "${{ env.infrastructure }}" \
            "${{ (env.volumeSize || inputs.volumeSize) }}"

      - name: Start image pipeline execution
        id: image
        run: |
          chmod +x ./.github/assets/shell/startImagePipelineExecution.sh
          source ./.github/assets/shell/startImagePipelineExecution.sh \
                "${{ (env.environment || inputs.environment) }}" \
                "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
                "${{ (env.imageBuilderImagesToKeep || inputs.imageBuilderImagesToKeep) }}" \
                "${{ env.needImageRebuild }}" \
                "${{ (env.imageBuilderForceRebuild || inputs.imageBuilderForceRebuild) }}"

      - name: Wait for image availability
        id: ami
        run: |
          set -eEBx
          source ./IMAGE-BUILDER.txt
          source ./.github/assets/shell/waitImageAvailable.sh \
              "${{ steps.image.outputs.image_arn }}" \
              "${{ (env.environment || inputs.environment) }}" \
              "${{ needs.CONSTANTS.outputs.repositoryNicename }}" \
              "${{ steps.image.outputs.pipeline_arn }}" \
              "${{ matrix.aws-region }}" \
              "${{ github.head_ref || github.ref_name }}"

      - name: Create ENV variables
        run: |
          while IFS= read -r line
          do
            # Convert the line to the desired format
            converted_line="echo \"$line\" >> \$GITHUB_ENV"
            # Append the converted line to the output file
            echo "$converted_line" >> "IMAGE-BUILDER.sh"
          done < "IMAGE-BUILDER.txt"
          cat IMAGE-BUILDER.sh

      - name: Upload IMAGE-BUILDER.sh artifact
        uses: actions/upload-artifact@v4
        with:
          name: IMAGE-BUILDER-${{ matrix.aws-region }}
          path: ./IMAGE-BUILDER.sh
  DEPLOY:
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.CONSTANTS.outputs.regionInformation) }}
    runs-on: ubuntu-latest
    needs: [ CONSTANTS, REGIONAL-NETWORKING, DATABASE, IMAGE-BUILDER, LOAD-BALANCERS, ACM-AND-ROUTE-53 ]
    steps:
      - name: Download variable overrides
        if: ${{ env.varsArtifactName != '' || inputs.varsArtifactName != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ (env.varsArtifactName || inputs.varsArtifactName) }}
          path: ./vars

      - name: Load variable overrides
        run: |
          shopt -s nullglob
          for f in ./vars/*.sh; do
            echo "Importing $f"
            cat "$f"
            source "$f"
          done

      - name: Configure AWS credentials for (${{ (env.accountName || inputs.accountName) }}) account (${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }})
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: "${{ (env.instanceDeploymentAccountOidcRole || inputs.instanceDeploymentAccountOidcRole) }}"
          role-session-name: github-actions-oidc-session
          aws-region: "${{ matrix.aws-region }}"
          mask-aws-account-id: 'no'

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          repository: MilesSystems/easy-aws-deployments

      - name: Download REGIONAL-NETWORKING artifact
        uses: actions/download-artifact@v4
        with:
          name: REGIONAL-NETWORKING-${{ matrix.aws-region }}
          path: ./

      - name: Download LOAD-BALANCERS artifact
        uses: actions/download-artifact@v4
        with:
          name: LOAD-BALANCERS-${{ matrix.aws-region }}
          path: ./

      - name: Download CERTIFICATES artifact
        uses: actions/download-artifact@v4
        with:
          name: CERTIFICATES-${{ matrix.aws-region }}
          path: ./

      - name: Download DATABASE artifact
        uses: actions/download-artifact@v4
        with:
          name: DATABASE-${{ matrix.aws-region }}
          path: ./

      - name: Download IMAGE-BUILDER artifact
        uses: actions/download-artifact@v4
        with:
          name: IMAGE-BUILDER-${{ matrix.aws-region }}
          path: ./

      - name: Import Artifacts
        id: read-subnets
        run: |
          cat ./REGIONAL-NETWORKING.sh
          source ./REGIONAL-NETWORKING.sh
          cat ./DATABASE.sh
          source ./DATABASE.sh
          cat ./IMAGE-BUILDER.sh
          source ./IMAGE-BUILDER.sh
          cat ./LOAD-BALANCERS.sh
          source ./LOAD-BALANCERS.sh
          cat ./CERTIFICATES.sh
          source ./CERTIFICATES.sh

      - name: Set execute permission for CF script
        run: chmod +x ./.github/assets/shell/createUpdateCFStack.sh

      - name: Calculate safe LoadBalancerRulePriority
        run: |
          PRIORITY="${{ (env.loadBalancerRulePriority || inputs.loadBalancerRulePriority) }}"
          if [[ "$PRIORITY" -eq -1 ]]; then
            HASHED_PRIORITY=$(echo "${{ github.repository }}-${{ github.ref_name }}-${{ github.run_number }}" | cksum | awk '{print $1 % 49000 + 1000}')
            echo "Using hashed LoadBalancerRulePriority: $HASHED_PRIORITY"
            echo "LOADBALANCER_RULE_PRIORITY=$HASHED_PRIORITY" >> $GITHUB_ENV
          else
            echo "Using provided LoadBalancerRulePriority: $PRIORITY"
            echo "LOADBALANCER_RULE_PRIORITY=$PRIORITY" >> $GITHUB_ENV
          fi

      - name: Deploy web stack (${{ github.run_number }})
        id: web
        run: |
          
          cat > ./deployUserDataScript <<'DEPLOY-BOOTSTRAP-EOF'
          ${{ (env.deployUserDataScript || inputs.deployUserDataScript) }}
          DEPLOY-BOOTSTRAP-EOF
          
          php ./.github/assets/php/createDeploymentUserDataYaml.php ./deployUserDataScript
          
          PARAMETERS_FILE=$( php ./.github/assets/php/createAwsJsonParametersFile.php \
                    --Environment=${{ (env.environment || inputs.environment) }} \
                    --RepositoryNicename=${{ needs.CONSTANTS.outputs.repositoryNicename }} \
                    --Version=${{ env.version }} \
                    --RunNumber=${{ github.run_number }} \
                    --Branch=${{ github.head_ref || github.ref_name }} \
                    --GitHubRunNumber=${{ github.run_number }} \
                    --VpcId=${{ env.vpc }} \
                    --CertificateArn=${{ env.certificates }} \
                    --RecipeVersion=${{ env.version }} \
                    --PrivateSubnets=${{ env.privateSubnet }} \
                    --AmazonLinuxAMI=${{ env.ami }} \
                    --MinSize=${{ (env.minimumRunningInstances || inputs.minimumRunningInstances) }} \
                    --MaxSize=${{ (env.maximumRunningInstances || inputs.maximumRunningInstances) }} \
                    --DesiredCapacity=${{ (env.desiredInstanceCapacity || inputs.desiredInstanceCapacity) }} \
                    --OnDemandBaseCapacity=${{ (env.onDemandBaseCapacity || inputs.onDemandBaseCapacity) }} \
                    --OnDemandPercentageAboveBaseCapacity=${{ (env.OnDemandPercentageAboveBaseCapacity || inputs.OnDemandPercentageAboveBaseCapacity) }} \
                    --InstanceType=${{ (env.instanceType || inputs.instanceType) }} \
                    --MaxCpu=${{ (env.cpuUtilizationToScale || inputs.cpuUtilizationToScale) }} \
                    --LoadBalancerRulePriority=${{ env.LOADBALANCER_RULE_PRIORITY }} \
                    --LoadBalancerHosts=${{ (env.domains || inputs.domains) }} \
                    --AddAlbListener=${{ (env.deployALB || inputs.deployALB) }} \
                    --HeartbeatTimeout=${{ (env.deployHeartbeatTimeout || inputs.deployHeartbeatTimeout) }} \
                    --CreationPolicyTimeout=${{ (env.deployCreationPolicyTimeout || inputs.deployCreationPolicyTimeout) }} \
                    --UpdatePolicyPauseTime=${{ (env.deployUpdatePolicyPauseTime || inputs.deployUpdatePolicyPauseTime) }} \
                    --AddNlbListener=${{ (env.deployNLB || inputs.deployNLB) }} )
          
          echo "Parameters file:"
          
          cat $PARAMETERS_FILE
          
          cat > ./deployTrackUserDataScript <<'DEPLOY-BOOTSTRAP-EOF' 
          ${{ (env.deployTrackUserDataScript || inputs.deployTrackUserDataScript) }}
          DEPLOY-BOOTSTRAP-EOF
          
          echo "Version (${{ env.version }})"
          
          source ./.github/assets/shell/stackWeb.sh "$PARAMETERS_FILE" \
            "${{ matrix.aws-region }}" "${{ (env.environment || inputs.environment) }}" "${{ needs.CONSTANTS.outputs.repositoryNicename }}" "${{ env.version }}" "${{ github.run_number }}" "./deployTrackUserDataScript"

      - name: EC2 auto-scaling instance refresh
        if: ${{ steps.web.outputs.refresh == '1' && needs.IMAGE-BUILDER.outputs.image_rebuilt == '1' }}
        run: |
          REFRESH_ID=$(aws autoscaling start-instance-refresh \
                --preferences '{"InstanceWarmup": 1200, "MinHealthyPercentage": 100}' \
                --strategy Rolling \
                --auto-scaling-group-name "${{ (env.environment || inputs.environment) }}-${{ needs.CONSTANTS.outputs.repositoryNicename }}-${{ env.version }}.${{ github.run_number }}-asg" --output text)

          TRY=-1

          getStatus() {
            STATUS=$(aws autoscaling describe-instance-refreshes \
                --instance-refresh-ids $REFRESH_ID \
                --query 'InstanceRefreshes[*]' \
                --auto-scaling-group-name "${{ (env.environment || inputs.environment) }}-${{ needs.CONSTANTS.outputs.repositoryNicename }}-${{ env.version }}.${{ github.run_number }}-asg" | jq '.[-1].Status' --raw-output)
            TRY=$((1 + TRY))
          }

          cat > ./deployTrackUserDataScript <<'INSTANCE-REFRESH-EOF'
          ${{ (env.deployTrackUserDataScript || inputs.deployTrackUserDataScript) }}
          INSTANCE-REFRESH-EOF
          
          echo "Echo ./deployTrackUserDataScript: $( cat ./deployTrackUserDataScript )"

          getLog() {
            source ./.github/assets/shell/logBootStatus.sh "${{ env.version }}" "${{ github.run_number }}" "./deployTrackUserDataScript"
          } 

          getStatus

          sleep 240

          while [[ "$STATUS" == "Pending" || "$STATUS" == "InProgress" ]]; do
              getLog ${{ env.version }}
              echo "Waiting 60 seconds... <$STATUS> (attempt:$TRY)"
              sleep 60
              getStatus
          done
          if [[ "$STATUS" == "Successful" ]]; then
            echo "Refresh successful"
            aws ec2 describe-instances --query 'Reservations[*].Instances[*]' --filters Name=instance-state-name,Values=running --output text
            exit 0
          else
            aws cloudformation describe-stack-events --stack-name ${STACK_NAME} --region ${REGION}
            echo "Refresh failed ($STATUS)"
            exit 1
          fi
